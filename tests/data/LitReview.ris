TY  - JOUR
TI  - Smart City Middleware: A Survey and a Conceptual Framework
AU  - Goumopoulos, Christos
T2  - IEEE Access
AB  - Smart city middleware serves as a foundational tool in the evolution of urban digitalization, acting as an intermediary software layer that simplifies the development, deployment, and management of applications tailored for smart urban environments. However, the development of effective middleware for smart cities is challenging. The present research embarks on a comprehensive exploration of the smart city middleware landscape, unraveling the intricacies of its development and the challenges faced therein. Rooted in the assessment of 20 distinct middleware solutions, our study highlights the pivotal technologies, features and functionalities that are imperative for a middleware to effectively support a city’s digital transformation. The functional and non-functional requirements form the nucleus of our evaluation. We also explore the architectural styles pivotal to middleware development and the programming paradigms shaping smart city application development. Our study highlights challenges in using middleware for smart city applications, such as interoperability, scalability, security amidst big data, context management, reliability, quality of service, energy efficiency, and compliance with technological standards and regulations. Based on the detailed analysis, we propose a conceptual framework for smart city middleware, shaped by the challenges and requirements identified in existing literature and middleware solutions. This framework is designed to reflect the diverse demands and complexities of urban digital transformation, and guide smart city middleware development accordingly. As a result, this research stands as a reference study for software developers, urban planners, and researchers, outlining the current state and future directions in the domain of smart city middleware.
DA  - 2024///
PY  - 2024
DO  - 10.1109/ACCESS.2023.3349376
DP  - DOI.org (Crossref)
VL  - 12
SP  - 4015
EP  - 4047
J2  - IEEE Access
LA  - en
SN  - 2169-3536
ST  - Smart City Middleware
UR  - https://ieeexplore.ieee.org/document/10379798/
Y2  - 2025/09/05/11:12:14
ER  -

TY  - JOUR
TI  - Urban flooding digital twin system framework
AU  - Ge, Chenyu
AU  - Qin, Shengfeng
T2  - Systems Science & Control Engineering
AB  - Digital twin-based resilience management systems are essential for improving urban flooding resilience, enabling lifecycle-oriented emergency management as a continuous process rather than discrete phases. However, to the best of our knowledge, currently, there lacks a system framework for supporting the development of an urban flooding digital twin (UFDT) platform capable of managing urban flooding events across the entire management lifecycle. This UFDT framework is required to (1) accommodate UFDT model-generation methods/tools for preparing what-if scenarios, (2) support readiness simulations and evaluations, (3) coordinate various collaborative prevention and intervention services from different stakeholders in response to any flooding emergence, and (4) monitor and forecast the flooding risks in the recovery phase. To fill this gap, in this paper, a new UFDT system framework is developed based on a user-centred product design process with the consideration of the above requirements. It has two key components: a UFDT conceptual model, and a generative methodology for its rapid construction/updating/adaptation to varying levels of detail. A framework prototype has been developed for testing the conceptual model at city, regional and street levels and exemplar generative methods/tools to assess the framework’s ability and potential to provide scalable, adaptable, and stakeholder-focused solutions to urban flooding resilience management[Q1].
DA  - 2025/12/31/
PY  - 2025
DO  - 10.1080/21642583.2025.2460432
DP  - DOI.org (Crossref)
VL  - 13
IS  - 1
SP  - 2460432
J2  - Systems Science & Control Engineering
LA  - en
SN  - 2164-2583
UR  - https://www.tandfonline.com/doi/full/10.1080/21642583.2025.2460432
Y2  - 2025/09/05/11:13:36
ER  -

TY  - JOUR
TI  - Knowledge integration via the fusion of the data models used in automotive production systems
AU  - Cupek, Rafal
AU  - Ziebinski, Adam
AU  - Drewniak, Marek
AU  - Fojcik, Marcin
T2  - Enterprise Information Systems
AB  - In this paper a novel information model that can be used in Manufacturing Execution Systems is presented. The model is based on the fusion of ISA95, AML and OPC UA. ISA95 is used to define, unify and describe the details of a product and production technology. It also enables communication with ERP systems. The AML standard allows information about the production facilities to be presented. The OPC UA address space represents different parts of an information model while the OPC communication protocol enables it to be linked to actual production systems. The proposed concept is illustrated using an actual example of a production line for electronic devices.
DA  - 2019/09/14/
PY  - 2019
DO  - 10.1080/17517575.2018.1489563
VL  - 13
IS  - 7-8
SP  - 1094
EP  - 1119
J2  - Enterprise Information Systems
SN  - 1751-7575
UR  - https://doi.org/10.1080/17517575.2018.1489563
N1  - <p>doi: 10.1080/17517575.2018.1489563</p>
ER  -

TY  - JOUR
TI  - Using Domain-Specific Models to Facilitate Model-Based Systems-Engineering: Development Process Design Modeling with OPM and PROVE
AU  - Shaked, Avi
AU  - Reich, Yoram
T2  - Applied Sciences
AB  - Model-based Systems Engineering (MBSE) approaches are a step forward in the evolution of computer-aided engineering, and yet, they often incorporate deﬁciencies that may jeopardize their practical utility and usability, as well as the validity of the resulting models. We demonstrate how a domain-speciﬁc modeling approach can relieve some hurdles in adopting MBSE, and how it can be used in tandem with a general-purpose modeling approach to augment and introduce rigor to models. Speciﬁcally, we demonstrate the consequences of theoretical issues that were previously identiﬁed in Object Process Methodology and suggest an approach to solve them. We use a generalized casestudy—derived from extensive process modeling in both academia and industry—to show that a domain-speciﬁc model can signiﬁcantly relax the user’s modeling effort. This demonstration is based on two quantitative metrics: the number of representational elements and available modeling tactics. We discuss the contribution of our approach to model quality, particularly with respect to its rigor and communicability.
DA  - 2021/02/08/
PY  - 2021
DO  - 10.3390/app11041532
DP  - DOI.org (Crossref)
VL  - 11
IS  - 4
SP  - 1532
J2  - Applied Sciences
LA  - en
SN  - 2076-3417
ST  - Using Domain-Specific Models to Facilitate Model-Based Systems-Engineering
UR  - https://www.mdpi.com/2076-3417/11/4/1532
Y2  - 2025/09/05/11:15:44
KW  - Not Included
ER  -

TY  - JOUR
TI  - Multi-domain information model
AU  - Markov, Krassimir
AB  - The “Multi-Domain Information Model” (MDIM) has been established twenty years ago. For a long period it has been used as a basis for organisation of various information bases. The first publication containing some details of MDIM is [Markov, 1984] but the model has not been fully presented till now. In addition, over the years, the model has been extended with some new concepts like “information space”, “metaindex”, “polyindexation”, etc. which we will introduce in this paper.  The present paper aims to present MDIM as a coherent whole.
DA  - 2004///
PY  - 2004
KW  - ⛔ No DOI found
ER  -

TY  - BOOK
TI  - Natural Language Addressing
AU  - Markov, Krassimir
AU  - Ivanova, Krassimira
AU  - Velychko, Vitalii
AU  - Vanhoof, Koen
AB  - Large unstructured or semi-structured datasets require a high level of computational
sophistication because operations that are easy at a small scale — such as moving data betweenmachines or in and out of storage, visualizing the data, or displaying results —can all require substantial algorithmic ingenuity. As a data set becomes increasingly massive, it may be infeasible to gather it in one place and analyze it as a whole. Thus, there may be a need for algorithms that operate in a distributed fashion, analyzing subsets of the data and aggregating those results to understand the complete set. One aspect of this is the challenge of data assimilation, in which we wish to use new data to update model parameters without reanalyzing the entire data set. This is essential when new waves of data continue to arrive, or subsets are analyzed in isolation of one another, and one aims to improve the model and inferences in an adaptive fashion — for example, with streaming algorithms [NRC, 2013].
DA  - 2015/11/05/
PY  - 2015
SN  - 978-954-16-0070-2 (printed), 978-954-16-0071-9 (online)
ER  -

TY  - JOUR
TI  - COMPARISON OF DISCRETIZATION METHODS FOR PREPROCESSING DATA FOR PYRAMIDAL GROWING NETWORK CLASSIFICATION METHOD
AU  - Mitov, Ilia
AU  - Ivanova, Krassimira
AU  - Markov, Krassimir
AU  - Velychko, Vitalii
AU  - Stanchev, Peter
AU  - Vanhoof, Koen
AB  - This paper presents a comparison of four representative discretization methods from different classes to be used with so called PGN-classifier which deals with categorical data. We examine which of them supplies more convenient discretization for PGN Classification Method. The experiments are provided on the base of UCI repository data sets. The comparison tests were provided using an experimental classification machine learning system "PaGaNe", which realizes Pyramidal Growing Network (PGN) Classification Algorithm. It is found that in general, PGN-classifier trained on data preprocessed by Chi-merge achieve lower classification error than those trained on data preprocessed by the other discretization methods. The comparison of PGN-classifier, trained with Chi-merge-discretizator with other classifiers (realized in WEKA system) shows good results in favor of PGNclassifier.
DP  - Zotero
IS  - 14
LA  - en
ER  -

TY  - CHAP
TI  - " PaGaNe"–a CLASSIFICATION MACHINE LEARNING SYSTEM BASED on the MULTIDIMENSIONAL NUMBERED INFORMATION SPACES
AU  - MITOV, ILIA
AU  - IVANOVA, KRASSIMIRA
AU  - MARKOV, KRASSIMIR
AU  - VELYCHKO, VITALII
AU  - VANHOOF, KOEN
AU  - STANCHEV, PETER
T2  - Intelligent decision making systems
AB  - A classification machine learning system "PaGaNe" based on the multidimensional numbered information spaces for memory structuring is presented in the paper. Testing results, which show the efficiency of chosen approach, are presented.
DA  - 2010///
PY  - 2010
SP  - 279
EP  - 286
PB  - World Scientific
ER  -

TY  - JOUR
TI  - ADVANCE OF THE ACCESS METHODS
AU  - Markov, Krassimir
AU  - Ivanova, Krassimira
AU  - Mitov, Ilia
AU  - Karastanev, Stefan
T2  - International Journal
AB  - The goal of this paper is to outline the advance of the access methods in the last ten years as well as to make review of all available in the accessible bibliography methods.
DA  - 2008///
PY  - 2008
DP  - Zotero
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - CONF
TI  - Multi-domain virtual network embedding with coordinated link mapping
AU  - Li, Shuopeng
AU  - Saidi, Mohand Yazid
AU  - Chen, Ken
AB  - Network Virtualization, which allows the coexistence of various logical networks on shared physical infrastructure, has become popular in recent years. The optimal mapping of virtual resource to physical resource is a major issue in network virtualization. This problem, called virtual network embedding (VNE), has been well explored in the context of one physical domain, which is in practice operated by a single infrastructure provider (InP). However, the needs of virtual network (VN) is rapidly growing, and quite a number of VNs have to be established across multi-domain. For multi-domain VNE, infrastructure providers can no longer just solve their own single domain VNE problem, but have to cooperate to build the whole VN. Therefore, new challenge arises for the multi-domain VNE, compared to traditional single domain VNE. The existing investigations on this problem mainly focus on decomposing a VN to sub VN for each domain, but little attention has been paid to the joint relation between intra-domain and inter-domain (peering) links. In this paper, we propose a multi-domain link mapping method which combines the intra and peering link mapping so as to optimize the overall resource utilization. Our approach is easy to be deployed since it is based on current Internet architecture. Evaluation shows that our approach brings improvements related to existing methods.
C3  - 2016 24th international conference on software, telecommunications and computer networks (SoftCOM)
DA  - 2016///
PY  - 2016
DO  - 10.1109/SOFTCOM.2016.7772158
SP  - 1
EP  - 6
KW  - Bandwidth
KW  - III-V semiconductor materials
KW  - Indium phosphide
KW  - Peer-to-peer computing
KW  - Substrates
KW  - Topology
KW  - Virtualization
ER  -

TY  - THES
TI  - Class association rule mining using multidimensional numbered information spaces
AU  - MITOV, Iliya
AB  - Data mining is of great importance in the overall process of knowledge discovery. In this dissertation we focused our attention in the part of discoveryoriented methods and especially classification algorithms. Class-Association Rules (CAR) algorithms have a special place within the family of classification algorithms. This type of classifiers offers a number of advantages: efficiency of the training regardless of the training set; easy handling with high dimensionality; very fast classification; high accuracy; classification model easily comprehensible for humans. The main classification workflow of CAR algorithms usually involves three phases: generating the rules, pruning, and recognition. The mining of association rules is a typical data mining task that works in an unsupervised manner. A major advantage of association rules is that they are theoretically capable to reveal all interesting relationships in a database. But for practical applications the number of mined rules is usually too large to be exploited entirely. Hence, a pruning phase is applied in order to build accurate and compact classifiers. The pruning can be applied during preprocessing, simultaneously to the association rules mining, or during post-processing. Different rule quality measures and rule ordering schemes can be applied in the process of rule selection. There are also different options which can be considered for the recognition phase – e.g. to use a simple rule or to use a set of rules with different types of ordering schemas. On the other hand, the process of creating classification models inevitably touches upon the use of appropriate access methods which facilitate access to different kinds of structures used in such algorithms. Our effort had been focused on the memory organization called Multidimensional numbered information spaces which allows to operate with contextfree multidimensional data structures. The program realization of such structures is named ArM 32. Multi-Domain Information Model (MDIM) and respectively Arm 32 are based on the process of replacing names by numbers which allows to use mathematical functions and addressing vectors for accessing the information. Our approach is to use such structures and operations in the implementation of one class association rule classifier in order to provide evidence on the vitality of the idea of using context-free multidimensional data structures and direct access as a powerful tool for knowledge discovery. We have proposed two classification algorithms – Pyramidal Growing Networks (PGN) and Multi-layer Pyramidal Growing Networks (MPGN). PGN creates association rules, optimized for maximal accuracy of produced rules. One of the main characteristics of PGN is that it is a parameter-free classifier. The association rule mining is executed from the longest rules to the shorter ones until no intersections between patterns in the classes are possible. In the pruning phase the contradictions and inconsistencies of more general rules are cleared, after that the pattern set is compacted excluding all more concrete rules within the classes. PGN is introduced as a useful tool for questioning the support-first principle used by many associative classifiers when mining for association rules. PGN reverses the common approach and focuses primarily on the confidence of the association rules and only in a later stage on the support of the rules. The main purpose is twofold: to provide a proof of concept for this new approach and to gather evidence on its potential. MPGN is based on multilayer structure. It involves possibility to escape combinatorial explosion using smart disposing of the information in the multilayer structures called "pyramids". These structures can be easily implemented using ArM-structures. These algorithms are implemented in the data mining environment PaGaNe, developed by the team from the Institute of Mathematics and Informatics – Bulgarian Academy of Sciences; Iliya Mitov and Krassimira Ivanova are the principal developers. PaGaNe incorporates different types of statistical analysis methods, discretization algorithms, association rule miner, as well as classification algorithms, which all are based on the use of multi-dimensional numbered information spaces. The Lenses dataset is used as a test example to illustrate the specifics of the proposed algorithms, the process of creating classification models as well as the process of recognition. We demonstrate that PGN produces the pattern set that is both minimal and complete for covering the learning set, which is an indicator for expectation that PGN will produce tight model and good accuracy results. In the case of MPGN we have demonstrated the process of creating main construction elements. We also have illustrated the functionality which allows to visualize how the pyramids are being created and how the queries are being recognized. We carried out experiments with 25 datasets from the UCI machine learning repository [Frank and Asuncion, 2010]. The experiments had been conducted using the data mining environment PaGaNe, the knowledge analysis system Weka, and LUCS-KDD Repository. A comparison between PGN, MPGN and some other CAR algorithms, as well as decision tree and decision rule classifiers which have similar behavior of creating the task model, had been done. One series of experiments aimed to study what accuracy had been obtained while preprocessing real data with different discretizators realized in PaGaNe. We found that in general PGN-classifier trained on data preprocessed by Chimerge with 95trained on data preprocessed by the other discretization methods. The main reason for this is that using Chi-square statistical measure as criterion for class dependency in adjacent intervals of a feature results in good separation between class labels. A second set of experiments studied the process of growing the learning sets and how this reflects on the classification model and the accuracy of PGN and MPGN; more specifically, we studied the critical point of the amount of the learning set in which classification model is relatively compact and the received accuracy stabilizes. Of course this critical point highly depends on the choice of dataset. A third set of experiments were focused on analyzing different exit points of MPGN. The received results showed that in a lot of cases the build constructs lead to excluding only one class as best competitor. Other cases usually fall into competition between classes, where different strategies for ordering the competitors can be applied. A very few cases fall into the way where MPGNalgorithm did not work and alternative choice is given. A fourth set of experiments aimed to analyze the dependencies of classifiers' behaviors when the noise rush in the dataset attributes; for this set we used the Monks1 dataset. The experiments demonstrated that noising in the dataset worsens considerably the accuracy of PGN which had been designed to perform well in clear datasets. However, experiments with other existing classifiers showed that they also were not been able to resist noising attacks. We made the comparison of overall accuracy between PGN, MPGN (with two recognition strategies – S1 and S2), CMAR, OneR, JRip, J48 and REPTree. The Friedman test showed statistical difference between tested classifiers. The post-hoc Nemenyi test showed that our PGN has best overall performance between examined classifiers and MPGN is competitive with CMAR, J48, JRip and REPTree. The experimental results are very positive and show that PGN is competitive with classification methods that build similar classification behavior. At the same time, it has an essential advantage over the other classifiers being parameter free. Furthermore, the empirical results showed that PGN is slightly more sensitive to noise than techniques such as C4.5 and RIPPER. However, its overall accuracy was still very good compared to these classifiers. In general, the results provide evidence that the confidence-first approach yields interesting opportunities for knowledge discovery.
DA  - 2011///
PY  - 2011
LA  - en
M3  - Phd thesis
ER  -

TY  - JOUR
TI  - Automated translation from domain knowledge to software model: EXCEL2UML in the tunneling domain
AU  - Paskaleva, Galina
AU  - Mazak-Huemer, Alexandra
AU  - Villeneuve, Marlène
AU  - Waldhart, Johannes
T2  - Journal of Information Technology in Construction
AB  - The development of software tools is a collaborative process involving both the domain experts and the software engineers. This requires efficient communication considering different expertise and perspectives. Additionally, the two groups utilize language and communication tools in disparate ways. This, in turn, may lead to hidden misunderstandings in the requirement analysis phase and potentially result in implementation problems later on, that is difficult and costly to correct. In this paper, we demonstrate the above mentioned challenge via a use case from the tunneling domain. In particular, during the requirement analysis phase for a software capable of handling the data model of the subsoil. The domain experts in the field can best express the complexity of their domain by describing its artifacts, which in most cases are incomprehensible to the software engineers. We outline a method that interleaves requirement analysis and software modeling to enable an iterative increase of the accuracy and completeness of the information extracted from those artifacts and integrated into a flexible software model, which can produce testable software code automatically. Furthermore, we present a prototypical implementation of our method and a preliminary evaluation of the approach.
DA  - 2023/07/14/
PY  - 2023
DO  - 10.36680/j.itcon.2023.019
DP  - DOI.org (Crossref)
VL  - 28
SP  - 360
EP  - 384
J2  - ITcon
LA  - en
SN  - 1874-4753
ST  - Automated translation from domain knowledge to software model
UR  - https://www.itcon.org/paper/2023/19
Y2  - 2025/09/05/11:35:03
ER  -

TY  - BOOK
TI  - About NL-addressing
AU  - IVANOVA, Krassimira
AU  - Velychko, Vitalii
AU  - MARKOV, Krassimir
T2  - Problems of computer intellectualization
AB  - В настоящей работе представлена идея естественно-языковой адресации. Это дополнительная возможность для представления онтологической информации в интеллектуальных системах. Естественно-языковая адресация имеет ряд преимуществ. На первом месте – это линейная алгоритмическая сложность, которая зависит от максимальной длины слов (max_L), а не от их количества. Во-вторых, это уменьшение объема занимаемой памяти – дополнительные индексы не используются. В-третьих, уменьшение времени обработки из-за полного отсутствия поиска – информация извлекается прямо по адресу. Необходимо отметить, что это универсальное представление информации одновременно доступной как для человека, так и для автоматизированных систем. Такой способ организации информации применим для ее хранения и использования в библиотеках онтологий, терминов, понятий, текстовых документов
CY  - Kiev, Ukraine - Sofia, Bulgaria
DA  - 2012///
PY  - 2012
LA  - other
PB  - ITHEA® 2012
SN  - 978-954-16-0061 0
KW  - Естественно-языковая адресация
KW  - организация онтологических баз данных
ER  -

TY  - CHAP
TI  - Storing RDF graphs using NL-addressing
AU  - IVANOVA, Krassimira
AU  - Velychko, Vitalii
AU  - MARKOV, Krassimir
T2  - Artificial intelligence methods and techniques for business and engineering applications
AB  - NL-addressing is a possibility to access information using natural language words as addresses of the information stored in the multi-dimensional numbered information spaces. For this purpose the internal encoding of the letters is used to generate corresponded co-ordinates. The tool for working in such style is named OntoArM. Its main principles, functions and using for storing RDF graphs are outlined in this paper
CY  - Rzeszow, Poland; Sofia, Bulgaria
DA  - 2012///
PY  - 2012
SP  - 84
EP  - 98
LA  - en
PB  - ITHEA® 2012
SN  - 978-954-16-0057-3
KW  - NL-addressing
KW  - ontology representations.
KW  - RDF graphs
ER  -

TY  - THES
TI  - Storing data using natural language addressing
AU  - IVANOVA, Krassimira
AB  - Large unstructured or semi-structured datasets require a high level of computational sophistication because operations that are easy at a small scale — such as moving data between machines or in and out of storage, visualizing the data, or displaying results —can all require substantial algorithmic ingenuity. As a data set becomes increasingly massive, it may be infeasible to gather it in one place and analyze it as a whole. Thus, there may be a need for algorithms that operate in a distributed fashion, analyzing subsets of the data and aggregating those results to understand the complete set. One aspect of this is the challenge of data assimilation, in which we wish to use new data to update model parameters without reanalyzing the entire data set. This is essential when new waves of data continue to arrive, or subsets are analyzed in isolation of one another, and one aims to improve the model and inferences in an adaptive fashion — for example, with streaming algorithms [NRC, 2013]. In accordance with the actuality of these problems, firstly in [Mitov, 2011] and after that in [Markov et al, 2013] a new idea has been proposed. It is a method for effective building and storing of pattern sets in multi-layer structures during the process of associative rule mining using the possibilities of multi-dimensional numbered information spaces. The main algorithm was called “MPGN”, an abbreviation from "Multi-layer Pyramidal Growing Networks of information spaces". The main goal was to extend the possibilities of network structures by using a special kind of multi-layer memory structures called "pyramids", which permits defining and realizing new opportunities. The bottleneck of MPGN became the need to search in billions of values of the association rules’ features to convert instances in numbered arrays (vectors). This is a part of preprocessing step of algorithm (see page 97 of [Mitov, 2011]). The process of numbering took considerable time. After numbering, the MPGN algorithm had shown very good results. This work is aimed to propose a solution of the problem of searching in big index structures by proposing a special kind of hashing, so-called “multi-layer hashing”, i.e. by implementing recursively the same specialized hash function to build and resolve the collisions in hash tables. In other words, the main idea consists in using the specialized hashing functions in depth till it is needed. This approach is called “Natural Language Addressing” (NLA) [Ivanova et al, 2012a; Ivanova et al, 2013a; Ivanova et al, 2013d]. The common sense meaning of the concept “address” is such as a description of the location (of a person or organization), as written or printed on mail as directions for delivery [AHD, 2009]; the conventional form by which the location of a building is described [Collins, 2003]; a sign in front of a house or business carrying the conventional form by which its location is described; [WordNet, 2012]. We will use the concept “address” in the sense accepted in the Computer Science: the code that identifies where a piece of information is stored [WordNet, 2012]; a name or number used in information storage or retrieval that is assigned to a specific memory location; the memory location identified by this name or number [AHD, 2009]. Natural Language Addressing (NLA) is a possibility to access information using natural language words as paths to the information. For this purpose the internal encoding of the letters is used to generate corresponded path. The idea of Natural Language Addressing (NL-Addressing) is very simple. It is based on the computer internal representation of the word as strings of codes in a system of encoding (ASCII, UNICODE, etc.). For example, the ASCII encoding of the word „accession” has the next representation: (97, 99, 99, 101, 115, 115, 105, 111, 110). It may be used as array for multi-layer hashing, which indicates a path to point, where the corresponded information may be stored. The main problem in such approach is that the words have different lengths and, in addition, several words may form one phrase and this way to be assumed as single concept. This means that we need tools for managing multi-layer hashing with variable path lengths in an integrated structure. Due to the complexity of MPGN algorithm and the corresponded program system realized in [Mitov, 2011], their redesign and reprogramming for using NLA have to be done after proving the efficiency of NLA realization. Because of this we will concern several types of semi-structured data: ― small datasets - dictionaries, thesauruses, ontologies; ― middle-size and large RDF triple or quadruple datasets, and will provide corresponded experiments and practical implementation. In accordance with this, the PhD research is aimed to propose information model for NL-addressing and corresponded access method as well as the tools for working in such style, theirs main principles, and storing functions. Results presented in this work were implemented in the Institute of Cybernetics V.M. Glushkov at the National Academy of Sciences of Ukraine, Kiev. They had been used for storing dictionaries, thesauruses, ontologies, and RDF-graphs, extracted from multiple documents from own databases as well as from different internet sources.
DA  - 2014///
PY  - 2014
LA  - en
M3  - Phd thesis
ER  -

TY  - JOUR
TI  - An Approach to Multi-Domain Data Model Development Based on the Model-Driven Architecture and Ontologies
AU  - Nikiforov, Denis A
AU  - Lisikh, Igor G
AU  - Sivakov, Ruslan L
AB  - To date, there are many diverse data representation technologies (EDIFACT, XML, JSON, CSV, relational model, NoSQL). Transition to new technologies or the integration of information systems based on different technological stacks is a complex and expensive process. Platform-independent models take an important role in this process. The structure of such a model is described in this article. However, given the data model has been created at the junction of different domains, it may be not enough. In such case, a one more step of abstraction and a movement to the computation-independent model is required. The authors propose to create it in an ontological form.
DA  - 2015///
PY  - 2015
DP  - Zotero
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - CONF
TI  - An Ontology-Driven Approach to Electronic Document Structure Design
AU  - Nikiforov, Denis A.
AU  - Korchagin, Alexander B.
AU  - Sivakov, Ruslan L.
A2  - Ignatov, Dmitry I.
A2  - Khachay, Mikhail Yu.
A2  - Labunets, Valeri G.
A2  - Loukachevitch, Natalia
A2  - Nikolenko, Sergey I.
A2  - Panchenko, Alexander
A2  - Savchenko, Andrey V.
A2  - Vorontsov, Konstantin
AB  - Over the course of history, humankind used documents as one of the ways of organization of the data. In the recent decades, electronic documentation became increasingly widespread. To make electronic documents exchange possible, standards regulating transmission protocols, representation formats, and rules for document building are necessary. For some protocols (HTTP, SOAP, etc.) and formats (EDI, XML, JSON, etc.), relatively fixed and generally accepted standards are available. As for the electronic document design, there is an abundance of approaches where a leader could hardly be established; all of them have their benefits and drawbacks. This study explores some of these approaches (UN/CEFACT CCTS, WCO DM, ISO 20022, and NIEM). These approaches have different features but from the conceptual perspective they are intended to describe sets of details of some real-world objects. The paper proposes to describe such objects using an ontology and then, based on this ontology, build conceptual structures of electronic documents that can be converted to platform-independent structures of electronic documents in accordance with one of the standards. The introduced approach allows harmonizing the standards under consideration.
C1  - Cham
C3  - Analysis of Images, Social Networks and Texts
DA  - 2017///
PY  - 2017
SP  - 3
EP  - 16
PB  - Springer International Publishing
SN  - 978-3-319-52920-2
ER  -

TY  - JOUR
TI  - THE B-TERMINAL BUSY PROBABILITY PREDICTION
AU  - Poryazov, Stoyan
T2  - International Journal
AB  - In the teletraffic engineering of all the telecommunication networks, parameters characterizing the terminal traffic are used. One of the most important of them is the probability of finding the called (B-terminal) busy. This parameter is studied in some of the first and last papers in Teletraffic Theory. We propose a solution in this topic in the case of (virtual) channel systems, such as PSTN and GSM. We propose a detailed conceptual traffic model and, based on it, an analytical macro-state model of the system in stationary state, with: Bernoulli–Poisson–Pascal input flow; repeated calls; limited number of homogeneous terminals; losses due to abandoned and interrupted dialling, blocked and interrupted switching, not available intent terminal, blocked and abandoned ringing and abandoned conversation. Proposed in this paper approach may help in determination of many network traffic characteristics at session level, in performance evaluation of the next generation mobile networks.
DP  - Zotero
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - RDFArM-a system for storing large sets of RDF triples and quadruples by means of natural language addressing
AU  - Ivanova, Krassimira
T2  - INFORMATION MODELS & ANALYSES
AB  - In this paper we present results from experiments for storing middle-size and large sets of RDF triples
and quadruples by means of Natural Language Addressing. For experiments we have realized program RDFArM
aimed to store RDF triples and quadruples in multi-layer hash tables (information spaces with variable size). The
main features of program RDFArM are outlined in the paper. Analysis of the experimental results and rank-based
multiple comparison are discussed.
DA  - 2012///
PY  - 2012
SP  - 303
KW  - ⛔ No DOI found
ER  -

TY  - CONF
TI  - ArmSquare: An association rule miner based on multidimensional numbered information spaces
AU  - MITOV, Iliya
AU  - IVANOVA, Krassimira
AU  - DEPAIRE, Benoit
AU  - VANHOOF, Koen
AB  - In this article, we propose a simple approach for association rule mining, which uses the possibilities of the multidimensional numbered information spaces as a storage structures. The main focus in the realization of ArmSquare is using the advantages of such spaces, i.e., the possibility to build growing space hierarchies of information elements, the great power for building interconnections between information elements stored in the information base, and the possibility to change searching with direct addressing in well structured tasks. The tested types of implementations of realized tool show the vividness of proposed approach.
C3  - Proceedings of the 1st international conference on advances in information mining and management
DA  - 2011///
PY  - 2011
SP  - 143
EP  - 148
LA  - en
PB  - Curran Associates, Inc.
SN  - 978-1-61839-702-7
N1  - 1st International Conference on Advances in Information Mining and Management
KW  - Association Rule Mining
KW  - Market Basket Analysis
KW  - Multidimensional Numbered Information Spaces
ER  -

TY  - JOUR
TI  - Increased efficiency in virtual commissioning with automated model generation based on component libraries
AU  - Pyschny, Nicolas
AU  - Rudat, Ben
AU  - Permin, Eike
T2  - Procedia CIRP
AB  - The use of Virtual Commissioning (VC) is becoming increasingly relevant for the engineering of automation systems. VC allows for validating concepts and design solutions in the early phases of product development, thereby improving communication among disciplines, reducing the costs for bug fixing and accelerating the overall engineering process, in particular the commissioning of plants and machines. However, as an additional software tool in engineering, the introduction of VC causes initial training and more importantly continuous extra modelling efforts. An approach to overcome this flaw is the automated generation of VC models based on existing engineering information from the system or domain level – ideally in tandem with the reuse of solution models from previous project. The latter can prove particularly beneficial in the context of modular building-block systems as often pursued in automation engineering.
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.procir.2022.05.258
DP  - DOI.org (Crossref)
VL  - 109
SP  - 328
EP  - 333
J2  - Procedia CIRP
LA  - en
SN  - 22128271
UR  - https://linkinghub.elsevier.com/retrieve/pii/S2212827122007077
Y2  - 2025/09/05/12:00:55
ER  -

TY  - JOUR
TI  - A SURVEY OF MATHEMATICAL AND INFORMATIONAL FOUNDATIONS OF THE BIGARM ACCESS METHOD
AU  - Ivanova, Krassimira
T2  - International Journal
AB  - The BigArM is an access method for storing and accessing Big Data. It is under development. In this survey we present its mathematical and informational foundations as well as its requirements to realization characteristics. Firstly, we outline the needed basic mathematical concepts, the Names Sets, and hierarchies of named sets aimed to create a specialized model for organization of information bases called “Multi-Domain Information Model” (MDIM). The “Information Spaces” defined in the model are kind of strong hierarchies of enumerations (named sets). Further we remember the main features of hashing and types of hash tables as well as the idea of “Dynamic perfect hashing” and “Trie”, especially – the “Burst trie”. Hash tables and tries give very good starting point. The main problem is that they are designed as structures in the main memory which has limited size, especially in small desktop and laptop computers. To solve this problem, dynamic perfect hashing and burst tries will be realized as external memory structures in BigArM.
DA  - 2015///
PY  - 2015
DP  - Zotero
VL  - 9
IS  - 3
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Multi-layer knowledge representation
AU  - Ivanova, Krassimira
T2  - International Journal “Information Content and Processing
AB  - An approach for knowledge representation based on post-relation type of information bases is outlined  in the paper. Explanation starts with remembering the idea of Natural Language Addressing. After that, the idea  of Multi-layer Knowledge Representation by Means of Natural Language Addressing is presented.
DA  - 2014///
PY  - 2014
VL  - 1
IS  - 4
SP  - 303
EP  - 310
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - OntoArM-a system for storing ontologies by natural language addressing
AU  - Ivanova, Krassimira
T2  - INFORMATION TECHNOLOGIES & KNOWLEDGE
AB  - In this paper we present results from experiments for storing RDF ontologies by means of Natural Language Addressing. For experiments we have realized system OntoArM aimed to store RDF triples in multilayer hash tables (information spaces with variable size). The main features of system OntoArM are outlined in the paper. Analysis of the experimental results concluded the work.
DA  - 2014///
PY  - 2014
SP  - 303
KW  - ⛔ No DOI found
ER  -

TY  - CHAP
TI  - Evaluating SPARQL-based model checking: Potentials and limitations
AU  - Hoffmann, A
AU  - Shi, M
AU  - Wagner, A
AU  - Thiele, C-D
AU  - Huyeng, T-J
AU  - Rüppel, U
AU  - Sprenger, W
T2  - ECPPM 2021-eWork and eBusiness in architecture, engineering and construction
AB  - Model checking is an important task in the BIM collaboration process to prevent expensive planning errors. The submodels of the individual disciplines are transferred into a coordination model. Part of the transfer is a conversion into an exchange format. The exchange format allows the import into the model checking application. In the model checking application routines are performed to check the model against collisions and building regulation violations. During the transfer into the exchange format, information may get lost, especially with parameters that are not yet part of the exchange format supported by the authoring software. In recent years, ontologies have been investigated as a feasible approach to combine the submodels, since they model data in a flexible manner. Hence in the conversion process to an application-specific ontology, the data structure of the submodels can widely persist, which could lead to smaller information loss in comparison to converting the data into a standardized exchange format. The evaluation of the geometric properties of the building is indispensable for detecting and analyzing collisions. The basis for the connection of the different sub models could be the BOT (Building Topology Ontology), which defines the topological structure of a building and can be used to represent further building information by linking it with other ontologies. The relevant geometric relationships for the collision model checks have to be derived with a geometry kernel. For the research in this paper pythonOCC, a wrapper for the geometry kernel Open CASCADE is used with the Semantic Web's own query language SPARQL, queries can be formulated to analyze the collision relationships in combination with other semantic information. These queries can be used to verify model correctness. By connecting the information from different domains, more sophisticated tests are possible than in an exchange format dependent model checking application. The goal is to integrate the developed functionalities into a project platform. This platform is based on an extensive project description in an ontology-based data model and is connected to different authoring tools for the exchange of information.
DA  - 2021///
PY  - 2021
SP  - 83
EP  - 90
PB  - CRC Press
ER  -

TY  - JOUR
TI  - Storing and Processing Accounting Information Based on Collect/Report Paradigm
AU  - Ivanova, Krassimira
T2  - International Journal
AB  - The possibility to store and process accounting information using the Collect/Report Paradigm (CRP) is outlined in this paper. The main idea consists of using CRP to distribute accounting information in multi-dimensional information spaces and stored and processed it in parallel in cloud. Every account may be presented by a separated layer which contains two named sets – Dr and Cr. Storing and reporting may be provided simultaneously without recompilation of the information base.
DA  - 2015///
PY  - 2015
DP  - Zotero
VL  - 2
IS  - 2
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - CONF
TI  - Building data warehouses using numbered information spaces
AU  - Markov, Krassimir
AB  - An approach for organizing the information in the data warehouses is presented in the paper.
The possibilities of the numbered information spaces for building data warehouses are discussed. An application
is outlined in the paper.
C3  - Fourth international conference INFORMATION RESEARCH and APPLICATIONS
DA  - 2006///
PY  - 2006
SP  - 201
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - ALGORITHM FOR QUICK NUMBERING OF LARGE VOLUMES OF DATA
AU  - Ivanova, Krassimira
T2  - International Journal
AB  - An original algorithm for numbering large datasets by means of Natural Language Addressing (NLA) is presented in the paper. We use a counter to number different instances and store its current value in the container NL-addressed by the instance. If the instance is repeated, from this NL-address we receive its already assigned number. The algorithm is implemented in an experimental program RDFArM for storing large RDF-datasets. The provided experiments have shown that NL-access time for one instance (triple or quadruple) does not depend on number of already stored instances from the dataset. This is very important for storing Big Data.
DA  - 2015///
PY  - 2015
DP  - Zotero
VL  - 22
IS  - 4
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Example of multi-layer knowledge representation by means of natural language addressing
AU  - Ivanova, Krassimira
T2  - ITHEA® Kyiv-Sofia, 2014
AB  - An approach for knowledge representation based on post-relation type of information bases is outlined in the paper. The idea of Natural Language Addressing and based on it idea of Multi-layer Knowledge Representation are presented.
DA  - 2014///
PY  - 2014
SP  - 115
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Managerial and Ontological Issues in the Development of Enterprise Architecture: Experiences from a Case Study
AU  - Hedman, Jonas
AU  - Schonström, Mikael
AB  - With increasing numbers and complexity of information models, it is becoming more and more important to have supporting modeling frameworks. Previous literature within this field has been descriptive, conceptual, and normative with few empirical studies addressing managerial and cognitive challenges during the development of large-scale models. This article addresses modeling from three perspectives: Enterprise Architecture (EA), Ontology, and Management Theory. The article presents the experiences from a large corporation effort to develop a modeling framework. The focus is on managerial and cognitive issues related to the development and use of the modeling framework. The conclusion is that large-scale modeling activities are complex involving several cognitive issues, such as managing different interpretations of terms due to different languages, modeling frameworks, cultures, and information systems.
DA  - 2013///
PY  - 2013
DP  - Zotero
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Data independence in the multi-dimensional numbered information spaces
AU  - Markov, Krassimir
AB  - The concept of data independence designates the techniques that allow data to be changed without affecting the applications that process it. The different structures of the information bases require corresponded tools for supporting data independence. A kind of information bases (the Multi-dimensional Numbered Information Spaces) are pointed in the paper. The data independence in such information bases is discussed.
DA  - 2008///
PY  - 2008
KW  - ⛔ No DOI found
ER  -

TY  - CONF
TI  - Multi-domain data modeling for biometrics
AU  - Chen, Alex
AU  - Kinser, Jason
AB  - Recently, much work has been performed on CBIR (content based image retrieval) that treats images as single data domain. However, in our highly digitized society, information is being supplied in multiple domains where the data is linked across domains. For example, a web site does contain images, but it may also contain text, hyperlinks, documents, sound files, movies, and other domains of data. Performing recall operations within single domains eliminates the possibility of employing cross-domain inferences. In this work, a multi-domain search space is presented in with two domains: speech and facial images. A single search space is created that contains data from these vastly different domains and cross-domain inferences are allowed. In other words, queries in the speech domain can retrieve image data even if there was no hard link between these data samples. Generation of multidomain search spaces will eventually expand CBIR systems to include data from a variety of sources.
C3  - 2011 IEEE applied imagery pattern recognition workshop (AIPR)
DA  - 2011/10//
PY  - 2011
DO  - 10.1109/AIPR.2011.6176354
SP  - 1
EP  - 5
KW  - Accuracy
KW  - Biometrics
KW  - Data domains
KW  - Data models
KW  - data query
KW  - Face
KW  - Image color analysis
KW  - IsoMap
KW  - Speech
KW  - Vectors
ER  -

TY  - CONF
TI  - Decentralization in industry 4.0 supported by opc ua multi-domain information models: Case study and implementation challenges
AU  - Pribiš, Rudolf
AU  - Beňo, Lukáš
AU  - Pajpach, Martin
AU  - Drahoš, Peter
AU  - Kocák, Ondrej
AB  - This paper introduces an OPC UA multi-domain information model aimed at supporting decentralization in industrial automation and includes a case study addressing the implementation challenges associated with integrating standards such as Device, PackML, ISA95, and AAS. The developed model enables interoperability and harmonization of information models across various domains, which is crucial for Industry 4.0 applications. The work highlights the paradox of decentralization, where independent modules require centralized control and data coordination, necessitating a unified information model. Key contributions include the proposal of methods to address technical challenges related to data type compatibility and inheritance of properties across domains. Additionally, the text emphasizes the importance of system integration for data acquisition from physical assets. A comparative analysis of implementation on PLCs, on-premises computing platforms, and cloud environments highlights tradeoffs in deployment depending on system complexity and response time requirements. The study results may assist in developing an information model for a decentralized unit in Industry 4.0.
C3  - 2025 cybernetics & informatics (K&I)
DA  - 2025/02//
PY  - 2025
DO  - 10.1109/KI64036.2025.10916421
SP  - 1
EP  - 6
KW  - Computational modeling
KW  - Data models
KW  - decentralization
KW  - Fourth Industrial Revolution
KW  - Industry 4.0
KW  - Interoperability
KW  - multi-domain information model
KW  - OPC UA
KW  - Proposals
KW  - Servers
KW  - Standards
KW  - Synchronization
KW  - System integration
KW  - Time factors
ER  -

TY  - JOUR
TI  - About two stereotypes of uml profile for multidimensional numbered data bases
AU  - Chebanyuk, Olena
AU  - Ivanova, Krassimira
AU  - Velychko, Vitalii
AU  - Markov, Krassimir
T2  - Ministry of Education and Science of Ukraine National Aviation University Software Engineering Department
AB  - Two stereotypes for Numbered Space (NSpace) and Space with Natural Language
Addressing (NLASpace) from an UML profile for modeling Multi-Dimensional Numbered Data Bases
(MDNDB™) are shortly outlined in this paper. MDNDB™ is a tool for storing Big Data locally as well as
in the cloud. Because of this, it is important to have appropriate modeling language to support the
design of practical applications.
DA  - 2019///
PY  - 2019
SP  - 30
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - From Concept to Reality: A Contemporary Framework for Virtual Designing and Commissioning Processing Plant Systems
AU  - Nielsen, Mads Kjærgaard
AU  - Beliatis, Michail J.
AU  - Tambo, Torben
T2  - Procedia Computer Science
AB  - The design and commissioning of process systems involve complex procedures often guided by digital Mock-Ups, replacing physical prototypes. This study presents a comprehensive framework integrating Virtual Commissioning, 3D CAD modeling, and industry standards to enhance the design process of such systems, supporting first-time-right implementations. The methodology combines literature review, industry standards, and case studies from the feed processing industry. The framework emphasizes interoperability, data model integrity, simulation, and cross-disciplinary communication. Findings suggest a refined model structure for modern manufacturing complexities, with practical implications for industry practitioners. Future research should refine the framework and explore broader industrial applications, improving implementation processes.
DA  - 2025///
PY  - 2025
DO  - 10.1016/j.procs.2025.01.159
DP  - DOI.org (Crossref)
VL  - 253
SP  - 974
EP  - 984
J2  - Procedia Computer Science
LA  - en
SN  - 18770509
ST  - From Concept to Reality
UR  - https://linkinghub.elsevier.com/retrieve/pii/S187705092500167X
Y2  - 2025/09/05/12:29:12
ER  -

TY  - CONF
TI  - Big data addressed in natural language
AU  - Markova, Vera
AU  - Ivanova, Krasimira
AU  - Karastanev, Stefan
AB  - Actions related to the cloud processing of large volumes of semi- or unstructured, streaming data (so-called “Big Data”) pose challenges that organizations must address. They are related to the location of the data in the cloud, its storage and management. Much of Big Data is collected from sources that are external to the business organization, such as social media, demographics, web data, events, news sources, and more. In this article, we discuss an access method to enable support for very large Big Data databases. It is based on the capabilities of Natural Language Addressing (NLA). An important advantage of NLA is the reduction of the amount of occupied memory due to the complete absence of additional indexes, absolute addresses, pointers and additional files, as well as the reduction of processing time due to the complete absence of searches - data is stored / retrieved to / from a direct address.
C3  - 2023 international conference on advanced enterprise information system (AEIS)
DA  - 2023/12//
PY  - 2023
DO  - 10.1109/AEIS61544.2023.00016
SP  - 53
EP  - 57
KW  - Big Data
KW  - big data databases
KW  - BigNLA access method
KW  - Data models
KW  - Memory management
KW  - natural language addressing
KW  - Natural languages
KW  - Organizations
KW  - Social networking (online)
KW  - Task analysis
ER  -

TY  - JOUR
TI  - BUILDING DATA WAREHOUSES USING NUMBERED INFORMATION SPACES
AU  - Mostovoi, Sergey V
T2  - International Journal
AB  - An approach for organizing the information in the data warehouses is presented in the paper. The possibilities of the numbered information spaces for building data warehouses are discussed. An application is outlined in the paper.
DP  - Zotero
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Distributed virtual laboratories for smart sensor system design
AU  - Palagin, Oleksandr
AU  - Romanov, Volodymyr
AU  - Velychko, Vitalii
AU  - Galelyuka, Igor
AU  - Fedak, Volodymyr
AU  - Grusha, Volodymyr
AU  - Artemenko, Dmytro
AU  - Galelyuka, Oksana
T2  - INFORMATION TECHNOLOGIES & KNOWLEDGE
AB  - In the article it is considered preconditions and main principles of creation of virtual laboratories for computer-aided design, as tools for interdisciplinary researches. An important feature of this project is using the advanced multi-dimensional access method for organizing the information base of the Virtual laboratory. Virtual laboratory, what are offered, is worth to be used on the stage of the requirements specification or EFT-stage, because it gives the possibility of fast estimating of the project realization, certain characteristics and, as a result, expected benefit of its applications. Using of these technologies already increase automation level of design stages of new devices for different purposes. Proposed computer technology gives possibility to specialists from such scientific fields, as chemistry, biology, biochemistry, physics etc, to check possibility of device creating on the basis of developed sensors. It lets to reduce terms and costs of designing of computer devices and systems on the early stages of designing, for example on the stage of requirements specification or EFT-stage.
An instance of using the VLCAD is designing the Portable Device" Floratest" as Tool for Estimating of Megalopolis Ecology State. Portable device" Floratest" is aimed for express-diagnostic of plant state. It is developed in the VM Glushkov Institute of Cybernetics of National Academy of Sciences of Ukraine. Party of this device is manufactured and transferred to organizations, worked in the agricultural sector, environmental protection area, mineral fertilizer production etc. for working out of methodical tools. Using of the device for estimating of megalopolis ecology state by means of evaluation of green plant state is described in the article. Together with Megalopolis Ecomonitoring and Biodiversity Research Center of National Academy of Sciences of Ukraine there were got results of experimental researches of influence detecting of heavy metals and harmful substances on the trees and plants in Kiev.
DA  - 2009///
PY  - 2009
SP  - 364
KW  - ⛔ No DOI found
ER  -

TY  - CHAP
TI  - Industrial Digitally Prototypes
AU  - Niemann, Jörg
AU  - Pisla, Adrian
T2  - Life-Cycle Management of Machines and Mechanisms
A2  - Niemann, Jörg
A2  - Pisla, Adrian
AB  - The whole product lifetime can be firstly defined into 5 major phases.
CY  - Cham
DA  - 2021///
PY  - 2021
SP  - 323
EP  - 353
PB  - Springer International Publishing
SN  - 978-3-030-56449-0
UR  - https://doi.org/10.1007/978-3-030-56449-0_17
ER  -

TY  - JOUR
TI  - Automatic Metadata Generation and Digital Cultural Heritage
AU  - Mitov, Iliya
AU  - Depaire, Benoit
AU  - Ivanova, Krassimira
AU  - Vanhoof, Koen
AU  - Blagoev, Dimitar
DA  - 2012///
PY  - 2012
DP  - Zotero
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - MULTI-VARIANT PYRAMIDAL CLUSTERING AND ANALYSIS HIGH-DIMENSIONAL DATA
AU  - Ivanova, Krassimira B
AU  - Velychko, Vitalii
AU  - Markov, Krassimir
T2  - International Journal
AB  - In this work an example of multi-variant clustering is presented. The problems to be solved are described and multi-variant clustering based on pyramidal multi-layer multi-dimensional structures is outlined. The conclusion is that the multi-variant clustering combined with pyramidal generalization and pruning gives reliable results.
DA  - 2012///
PY  - 2012
DP  - Zotero
VL  - 19
IS  - 1
LA  - en
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Smart city middleware: a survey and a conceptual framework
AU  - Goumopoulos, Christos
T2  - IEEE access : practical innovations, open solutions
AB  - Smart city middleware serves as a foundational tool in the evolution of urban digitalization, acting as an intermediary software layer that simplifies the development, deployment, and management of applications tailored for smart urban environments. However, the development of effective middleware for smart cities is challenging. The present research embarks on a comprehensive exploration of the smart city middleware landscape, unraveling the intricacies of its development and the challenges faced therein. Rooted in the assessment of 20 distinct middleware solutions, our study highlights the pivotal technologies, features and functionalities that are imperative for a middleware to effectively support a city’s digital transformation. The functional and non-functional requirements form the nucleus of our evaluation. We also explore the architectural styles pivotal to middleware development and the programming paradigms shaping smart city application development. Our study highlights challenges in using middleware for smart city applications, such as interoperability, scalability, security amidst big data, context management, reliability, quality of service, energy efficiency, and compliance with technological standards and regulations. Based on the detailed analysis, we propose a conceptual framework for smart city middleware, shaped by the challenges and requirements identified in existing literature and middleware solutions. This framework is designed to reflect the diverse demands and complexities of urban digital transformation, and guide smart city middleware development accordingly. As a result, this research stands as a reference study for software developers, urban planners, and researchers, outlining the current state and future directions in the domain of smart city middleware.
DA  - 2024///
PY  - 2024
DO  - 10.1109/ACCESS.2023.3349376
VL  - 12
SP  - 4015
EP  - 4047
J2  - IEEE Access
LA  - en
SN  - 2169-3536
UR  - https://ieeexplore.ieee.org/document/10379798/
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Included"
ER  -

TY  - JOUR
TI  - Urban flooding digital twin system framework
AU  - Ge, Chenyu
AU  - Qin, Shengfeng
T2  - Systems Science & Control Engineering
AB  - Digital twin-based resilience management systems are essential for improving urban flooding resilience, enabling lifecycle-oriented emergency management as a continuous process rather than discrete phases. However, to the best of our knowledge, currently, there lacks a system framework for supporting the development of an urban flooding digital twin (UFDT) platform capable of managing urban flooding events across the entire management lifecycle. This UFDT framework is required to (1) accommodate UFDT model-generation methods/tools for preparing what-if scenarios, (2) support readiness simulations and evaluations, (3) coordinate various collaborative prevention and intervention services from different stakeholders in response to any flooding emergence, and (4) monitor and forecast the flooding risks in the recovery phase. To fill this gap, in this paper, a new UFDT system framework is developed based on a user-centred product design process with the consideration of the above requirements. It has two key components: a UFDT conceptual model, and a generative methodology for its rapid construction/updating/adaptation to varying levels of detail. A framework prototype has been developed for testing the conceptual model at city, regional and street levels and exemplar generative methods/tools to assess the framework’s ability and potential to provide scalable, adaptable, and stakeholder-focused solutions to urban flooding resilience management[Q1].
DA  - 2025/12//
PY  - 2025
DO  - 10.1080/21642583.2025.2460432
VL  - 13
IS  - 1
SP  - 2460432
LA  - en
SN  - 2164-2583
UR  - https://www.tandfonline.com/doi/full/10.1080/21642583.2025.2460432
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Maybe"
ER  -

TY  - JOUR
TI  - Knowledge integration via the fusion of the data models used in automotive production systems
AU  - Cupek, Rafal
AU  - Ziebinski, Adam
AU  - Drewniak, Marek
AU  - Fojcik, Marcin
T2  - Enterprise Information Systems
AB  - In this paper a novel information model that can be used in Manufacturing Execution Systems is presented. The model is based on the fusion of ISA95, AML and OPC UA. ISA95 is used to define, unify and describe the details of a product and production technology. It also enables communication with ERP systems. The AML standard allows information about the production facilities to be presented. The OPC UA address space represents different parts of an information model while the OPC communication protocol enables it to be linked to actual production systems. The proposed concept is illustrated using an actual example of a production line for electronic devices.
DA  - 2019/09//
PY  - 2019
DO  - 10.1080/17517575.2018.1489563
VL  - 13
IS  - 7
SP  - 1094
EP  - 1119
SN  - 1751-7575
UR  - https://doi.org/10.1080/17517575.2018.1489563
N1  - ¡p¿doi: 10.1080/17517575.2018.1489563¡/p¿ | RAYYAN-INCLUSION: "Arjen"=¿"Maybe"
ER  -

TY  - JOUR
TI  - Using domain-specific models to facilitate model-based systems-engineering: Development process design modeling with OPM and PROVE
AU  - Shaked, Avi
AU  - Reich, Yoram
T2  - Applied Sciences
AB  - Model-based Systems Engineering (MBSE) approaches are a step forward in the evolution of computer-aided engineering, and yet, they often incorporate deﬁciencies that may jeopardize their practical utility and usability, as well as the validity of the resulting models. We demonstrate how a domain-speciﬁc modeling approach can relieve some hurdles in adopting MBSE, and how it can be used in tandem with a general-purpose modeling approach to augment and introduce rigor to models. Speciﬁcally, we demonstrate the consequences of theoretical issues that were previously identiﬁed in Object Process Methodology and suggest an approach to solve them. We use a generalized casestudy—derived from extensive process modeling in both academia and industry—to show that a domain-speciﬁc model can signiﬁcantly relax the user’s modeling effort. This demonstration is based on two quantitative metrics: the number of representational elements and available modeling tactics. We discuss the contribution of our approach to model quality, particularly with respect to its rigor and communicability.
DA  - 2021/02//
PY  - 2021
DO  - 10.3390/app11041532
VL  - 11
IS  - 4
SP  - 1532
LA  - en
SN  - 2076-3417
UR  - https://www.mdpi.com/2076-3417/11/4/1532
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Included"
ER  -

TY  - JOUR
TI  - Multi-domain information model
AU  - Markov, Krassimir
AB  - The “Multi-Domain Information Model” (MDIM) has been established twenty years ago. For a long period it has been used as a basis for organisation of various information bases. The first publication containing some details of MDIM is [Markov, 1984] but the model has not been fully presented till now. In addition, over the years, the model has been extended with some new concepts like “information space”, “metaindex”, “polyindexation”, etc. which we will introduce in this paper. The present paper aims to present MDIM as a coherent whole.
DA  - 2004///
PY  - 2004
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Maybe"
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Natural language addressing
AU  - Markov, Krassimir
AU  - Ivanova, Krassimira
AU  - Velychko, Vitalii
AU  - Vanhoof, Koen
AB  - Large unstructured or semi-structured datasets require a high level of computational sophistication because operations that are easy at a small scale — such as moving data betweenmachines or in and out of storage, visualizing the data, or displaying results —can all require substantial algorithmic ingenuity. As a data set becomes increasingly massive, it may be infeasible to gather it in one place and analyze it as a whole. Thus, there may be a need for algorithms that operate in a distributed fashion, analyzing subsets of the data and aggregating those results to understand the complete set. One aspect of this is the challenge of data assimilation, in which we wish to use new data to update model parameters without reanalyzing the entire data set. This is essential when new waves of data continue to arrive, or subsets are analyzed in isolation of one another, and one aims to improve the model and inferences in an adaptive fashion — for example, with streaming algorithms [NRC, 2013].
DA  - 2015/11//
PY  - 2015
SN  - 978-954-16-0070-2 (printed), 978-954-16-0071-9 (online)
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Comparison of discretization methods for preprocessing data for pyramidal growing network classification method
AU  - Mitov, Ilia
AU  - Ivanova, Krassimira
AU  - Markov, Krassimir
AU  - Velychko, Vitalii
AU  - Stanchev, Peter
AU  - Vanhoof, Koen
AB  - This paper presents a comparison of four representative discretization methods from different classes to be used with so called PGN-classifier which deals with categorical data. We examine which of them supplies more convenient discretization for PGN Classification Method. The experiments are provided on the base of UCI repository data sets. The comparison tests were provided using an experimental classification machine learning system "PaGaNe", which realizes Pyramidal Growing Network (PGN) Classification Algorithm. It is found that in general, PGN-classifier trained on data preprocessed by Chi-merge achieve lower classification error than those trained on data preprocessed by the other discretization methods. The comparison of PGN-classifier, trained with Chi-merge-discretizator with other classifiers (realized in WEKA system) shows good results in favor of PGNclassifier.
IS  - 14
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
ER  -

TY  - JOUR
TI  - " PaGaNe"–a CLASSIFICATION MACHINE LEARNING SYSTEM BASED on the MULTIDIMENSIONAL NUMBERED INFORMATION SPACES
AU  - MITOV, ILIA
AU  - IVANOVA, KRASSIMIRA
AU  - MARKOV, KRASSIMIR
AU  - VELYCHKO, VITALII
AU  - VANHOOF, KOEN
AU  - STANCHEV, PETER
T2  - Intelligent decision making systems
AB  - A classification machine learning system "PaGaNe" based on the multidimensional numbered information spaces for memory structuring is presented in the paper. Testing results, which show the efficiency of chosen approach, are presented.
DA  - 2010///
PY  - 2010
SP  - 279
EP  - 286
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Advance of the access methods
AU  - Markov, Krassimir
AU  - Ivanova, Krassimira
AU  - Mitov, Ilia
AU  - Karastanev, Stefan
T2  - International Journal
AB  - The goal of this paper is to outline the advance of the access methods in the last ten years as well as to make review of all available in the accessible bibliography methods.
DA  - 2008///
PY  - 2008
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Multi-domain virtual network embedding with coordinated link mapping
AU  - Li, Shuopeng
AU  - Saidi, Mohand Yazid
AU  - Chen, Ken
AB  - Network Virtualization, which allows the coexistence of various logical networks on shared physical infrastructure, has become popular in recent years. The optimal mapping of virtual resource to physical resource is a major issue in network virtualization. This problem, called virtual network embedding (VNE), has been well explored in the context of one physical domain, which is in practice operated by a single infrastructure provider (InP). However, the needs of virtual network (VN) is rapidly growing, and quite a number of VNs have to be established across multi-domain. For multi-domain VNE, infrastructure providers can no longer just solve their own single domain VNE problem, but have to cooperate to build the whole VN. Therefore, new challenge arises for the multi-domain VNE, compared to traditional single domain VNE. The existing investigations on this problem mainly focus on decomposing a VN to sub VN for each domain, but little attention has been paid to the joint relation between intra-domain and inter-domain (peering) links. In this paper, we propose a multi-domain link mapping method which combines the intra and peering link mapping so as to optimize the overall resource utilization. Our approach is easy to be deployed since it is based on current Internet architecture. Evaluation shows that our approach brings improvements related to existing methods.
DA  - 2016///
PY  - 2016
DO  - 10.1109/SOFTCOM.2016.7772158
SP  - 1
EP  - 6
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - Bandwidth
KW  - III-V semiconductor materials
KW  - Indium phosphide
KW  - Peer-to-peer computing
KW  - Substrates
KW  - Topology
KW  - Virtualization
ER  -

TY  - JOUR
TI  - Class association rule mining using multidimensional numbered information spaces
AU  - MITOV, Iliya
AB  - Data mining is of great importance in the overall process of knowledge discovery. In this dissertation we focused our attention in the part of discoveryoriented methods and especially classification algorithms. Class-Association Rules (CAR) algorithms have a special place within the family of classification algorithms. This type of classifiers offers a number of advantages: efficiency of the training regardless of the training set; easy handling with high dimensionality; very fast classification; high accuracy; classification model easily comprehensible for humans. The main classification workflow of CAR algorithms usually involves three phases: generating the rules, pruning, and recognition. The mining of association rules is a typical data mining task that works in an unsupervised manner. A major advantage of association rules is that they are theoretically capable to reveal all interesting relationships in a database. But for practical applications the number of mined rules is usually too large to be exploited entirely. Hence, a pruning phase is applied in order to build accurate and compact classifiers. The pruning can be applied during preprocessing, simultaneously to the association rules mining, or during post-processing. Different rule quality measures and rule ordering schemes can be applied in the process of rule selection. There are also different options which can be considered for the recognition phase – e.g. to use a simple rule or to use a set of rules with different types of ordering schemas. On the other hand, the process of creating classification models inevitably touches upon the use of appropriate access methods which facilitate access to different kinds of structures used in such algorithms. Our effort had been focused on the memory organization called Multidimensional numbered information spaces which allows to operate with contextfree multidimensional data structures. The program realization of such structures is named ArM 32. Multi-Domain Information Model (MDIM) and respectively Arm 32 are based on the process of replacing names by numbers which allows to use mathematical functions and addressing vectors for accessing the information. Our approach is to use such structures and operations in the implementation of one class association rule classifier in order to provide evidence on the vitality of the idea of using context-free multidimensional data structures and direct access as a powerful tool for knowledge discovery. We have proposed two classification algorithms – Pyramidal Growing Networks (PGN) and Multi-layer Pyramidal Growing Networks (MPGN). PGN creates association rules, optimized for maximal accuracy of produced rules. One of the main characteristics of PGN is that it is a parameter-free classifier. The association rule mining is executed from the longest rules to the shorter ones until no intersections between patterns in the classes are possible. In the pruning phase the contradictions and inconsistencies of more general rules are cleared, after that the pattern set is compacted excluding all more concrete rules within the classes. PGN is introduced as a useful tool for questioning the support-first principle used by many associative classifiers when mining for association rules. PGN reverses the common approach and focuses primarily on the confidence of the association rules and only in a later stage on the support of the rules. The main purpose is twofold: to provide a proof of concept for this new approach and to gather evidence on its potential. MPGN is based on multilayer structure. It involves possibility to escape combinatorial explosion using smart disposing of the information in the multilayer structures called "pyramids". These structures can be easily implemented using ArM-structures. These algorithms are implemented in the data mining environment PaGaNe, developed by the team from the Institute of Mathematics and Informatics – Bulgarian Academy of Sciences; Iliya Mitov and Krassimira Ivanova are the principal developers. PaGaNe incorporates different types of statistical analysis methods, discretization algorithms, association rule miner, as well as classification algorithms, which all are based on the use of multi-dimensional numbered information spaces. The Lenses dataset is used as a test example to illustrate the specifics of the proposed algorithms, the process of creating classification models as well as the process of recognition. We demonstrate that PGN produces the pattern set that is both minimal and complete for covering the learning set, which is an indicator for expectation that PGN will produce tight model and good accuracy results. In the case of MPGN we have demonstrated the process of creating main construction elements. We also have illustrated the functionality which allows to visualize how the pyramids are being created and how the queries are being recognized. We carried out experiments with 25 datasets from the UCI machine learning repository [Frank and Asuncion, 2010]. The experiments had been conducted using the data mining environment PaGaNe, the knowledge analysis system Weka, and LUCS-KDD Repository. A comparison between PGN, MPGN and some other CAR algorithms, as well as decision tree and decision rule classifiers which have similar behavior of creating the task model, had been done. One series of experiments aimed to study what accuracy had been obtained while preprocessing real data with different discretizators realized in PaGaNe. We found that in general PGN-classifier trained on data preprocessed by Chimerge with 95trained on data preprocessed by the other discretization methods. The main reason for this is that using Chi-square statistical measure as criterion for class dependency in adjacent intervals of a feature results in good separation between class labels. A second set of experiments studied the process of growing the learning sets and how this reflects on the classification model and the accuracy of PGN and MPGN; more specifically, we studied the critical point of the amount of the learning set in which classification model is relatively compact and the received accuracy stabilizes. Of course this critical point highly depends on the choice of dataset. A third set of experiments were focused on analyzing different exit points of MPGN. The received results showed that in a lot of cases the build constructs lead to excluding only one class as best competitor. Other cases usually fall into competition between classes, where different strategies for ordering the competitors can be applied. A very few cases fall into the way where MPGNalgorithm did not work and alternative choice is given. A fourth set of experiments aimed to analyze the dependencies of classifiers' behaviors when the noise rush in the dataset attributes; for this set we used the Monks1 dataset. The experiments demonstrated that noising in the dataset worsens considerably the accuracy of PGN which had been designed to perform well in clear datasets. However, experiments with other existing classifiers showed that they also were not been able to resist noising attacks. We made the comparison of overall accuracy between PGN, MPGN (with two recognition strategies – S1 and S2), CMAR, OneR, JRip, J48 and REPTree. The Friedman test showed statistical difference between tested classifiers. The post-hoc Nemenyi test showed that our PGN has best overall performance between examined classifiers and MPGN is competitive with CMAR, J48, JRip and REPTree. The experimental results are very positive and show that PGN is competitive with classification methods that build similar classification behavior. At the same time, it has an essential advantage over the other classifiers being parameter free. Furthermore, the empirical results showed that PGN is slightly more sensitive to noise than techniques such as C4.5 and RIPPER. However, its overall accuracy was still very good compared to these classifiers. In general, the results provide evidence that the confidence-first approach yields interesting opportunities for knowledge discovery.
DA  - 2011///
PY  - 2011
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Automated translation from domain knowledge to software model: EXCEL2UML in the tunneling domain
AU  - Paskaleva, Galina
AU  - Mazak-Huemer, Alexandra
AU  - Villeneuve, Marlène
AU  - Waldhart, Johannes
T2  - Journal of Information Technology in Construction
AB  - The development of software tools is a collaborative process involving both the domain experts and the software engineers. This requires efficient communication considering different expertise and perspectives. Additionally, the two groups utilize language and communication tools in disparate ways. This, in turn, may lead to hidden misunderstandings in the requirement analysis phase and potentially result in implementation problems later on, that is difficult and costly to correct. In this paper, we demonstrate the above mentioned challenge via a use case from the tunneling domain. In particular, during the requirement analysis phase for a software capable of handling the data model of the subsoil. The domain experts in the field can best express the complexity of their domain by describing its artifacts, which in most cases are incomprehensible to the software engineers. We outline a method that interleaves requirement analysis and software modeling to enable an iterative increase of the accuracy and completeness of the information extracted from those artifacts and integrated into a flexible software model, which can produce testable software code automatically. Furthermore, we present a prototypical implementation of our method and a preliminary evaluation of the approach.
DA  - 2023/07//
PY  - 2023
DO  - 10.36680/j.itcon.2023.019
VL  - 28
SP  - 360
EP  - 384
LA  - en
SN  - 1874-4753
UR  - https://www.itcon.org/paper/2023/19
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Maybe"
ER  -

TY  - JOUR
TI  - About NL-addressing
AU  - IVANOVA, Krassimira
AU  - Velychko, Vitalii
AU  - MARKOV, Krassimir
T2  - Problems of computer intellectualization
AB  - В настоящей работе представлена идея естественно-языковой адресации. Это дополнительная возможность для представления онтологической информации в интеллектуальных системах. Естественно-языковая адресация имеет ряд преимуществ. На первом месте – это линейная алгоритмическая сложность, которая зависит от максимальной длины слов (max_L), а не от их количества. Во-вторых, это уменьшение объема занимаемой памяти – дополнительные индексы не используются. В-третьих, уменьшение времени обработки из-за полного отсутствия поиска – информация извлекается прямо по адресу. Необходимо отметить, что это универсальное представление информации одновременно доступной как для человека, так и для автоматизированных систем. Такой способ организации информации применим для ее хранения и использования в библиотеках онтологий, терминов, понятий, текстовых документов
DA  - 2012///
PY  - 2012
LA  - other
SN  - 978-954-16-0061 0
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: foreign language
KW  - ⛔ No DOI found
KW  - Естественно-языковая адресация
KW  - организация онтологических баз данных
ER  -

TY  - JOUR
TI  - Storing RDF graphs using NL-addressing
AU  - IVANOVA, Krassimira
AU  - Velychko, Vitalii
AU  - MARKOV, Krassimir
T2  - Artificial intelligence methods and techniques for business and engineering applications
AB  - NL-addressing is a possibility to access information using natural language words as addresses of the information stored in the multi-dimensional numbered information spaces. For this purpose the internal encoding of the letters is used to generate corresponded co-ordinates. The tool for working in such style is named OntoArM. Its main principles, functions and using for storing RDF graphs are outlined in this paper
DA  - 2012///
PY  - 2012
SP  - 84
EP  - 98
LA  - en
SN  - 978-954-16-0057-3
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
KW  - NL-addressing
KW  - ontology representations.
KW  - RDF graphs
ER  -

TY  - JOUR
TI  - Storing data using natural language addressing
AU  - IVANOVA, Krassimira
AB  - Large unstructured or semi-structured datasets require a high level of computational sophistication because operations that are easy at a small scale — such as moving data between machines or in and out of storage, visualizing the data, or displaying results —can all require substantial algorithmic ingenuity. As a data set becomes increasingly massive, it may be infeasible to gather it in one place and analyze it as a whole. Thus, there may be a need for algorithms that operate in a distributed fashion, analyzing subsets of the data and aggregating those results to understand the complete set. One aspect of this is the challenge of data assimilation, in which we wish to use new data to update model parameters without reanalyzing the entire data set. This is essential when new waves of data continue to arrive, or subsets are analyzed in isolation of one another, and one aims to improve the model and inferences in an adaptive fashion — for example, with streaming algorithms [NRC, 2013]. In accordance with the actuality of these problems, firstly in [Mitov, 2011] and after that in [Markov et al, 2013] a new idea has been proposed. It is a method for effective building and storing of pattern sets in multi-layer structures during the process of associative rule mining using the possibilities of multi-dimensional numbered information spaces. The main algorithm was called “MPGN”, an abbreviation from "Multi-layer Pyramidal Growing Networks of information spaces". The main goal was to extend the possibilities of network structures by using a special kind of multi-layer memory structures called "pyramids", which permits defining and realizing new opportunities. The bottleneck of MPGN became the need to search in billions of values of the association rules’ features to convert instances in numbered arrays (vectors). This is a part of preprocessing step of algorithm (see page 97 of [Mitov, 2011]). The process of numbering took considerable time. After numbering, the MPGN algorithm had shown very good results. This work is aimed to propose a solution of the problem of searching in big index structures by proposing a special kind of hashing, so-called “multi-layer hashing”, i.e. by implementing recursively the same specialized hash function to build and resolve the collisions in hash tables. In other words, the main idea consists in using the specialized hashing functions in depth till it is needed. This approach is called “Natural Language Addressing” (NLA) [Ivanova et al, 2012a; Ivanova et al, 2013a; Ivanova et al, 2013d]. The common sense meaning of the concept “address” is such as a description of the location (of a person or organization), as written or printed on mail as directions for delivery [AHD, 2009]; the conventional form by which the location of a building is described [Collins, 2003]; a sign in front of a house or business carrying the conventional form by which its location is described; [WordNet, 2012]. We will use the concept “address” in the sense accepted in the Computer Science: the code that identifies where a piece of information is stored [WordNet, 2012]; a name or number used in information storage or retrieval that is assigned to a specific memory location; the memory location identified by this name or number [AHD, 2009]. Natural Language Addressing (NLA) is a possibility to access information using natural language words as paths to the information. For this purpose the internal encoding of the letters is used to generate corresponded path. The idea of Natural Language Addressing (NL-Addressing) is very simple. It is based on the computer internal representation of the word as strings of codes in a system of encoding (ASCII, UNICODE, etc.). For example, the ASCII encoding of the word „accession” has the next representation: (97, 99, 99, 101, 115, 115, 105, 111, 110). It may be used as array for multi-layer hashing, which indicates a path to point, where the corresponded information may be stored. The main problem in such approach is that the words have different lengths and, in addition, several words may form one phrase and this way to be assumed as single concept. This means that we need tools for managing multi-layer hashing with variable path lengths in an integrated structure. Due to the complexity of MPGN algorithm and the corresponded program system realized in [Mitov, 2011], their redesign and reprogramming for using NLA have to be done after proving the efficiency of NLA realization. Because of this we will concern several types of semi-structured data: ― small datasets - dictionaries, thesauruses, ontologies; ― middle-size and large RDF triple or quadruple datasets, and will provide corresponded experiments and practical implementation. In accordance with this, the PhD research is aimed to propose information model for NL-addressing and corresponded access method as well as the tools for working in such style, theirs main principles, and storing functions. Results presented in this work were implemented in the Institute of Cybernetics V.M. Glushkov at the National Academy of Sciences of Ukraine, Kiev. They had been used for storing dictionaries, thesauruses, ontologies, and RDF-graphs, extracted from multiple documents from own databases as well as from different internet sources.
DA  - 2014///
PY  - 2014
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - An approach to multi-domain data model development based on the model-driven architecture and ontologies
AU  - Nikiforov, Denis A
AU  - Lisikh, Igor G
AU  - Sivakov, Ruslan L
AB  - To date, there are many diverse data representation technologies (EDIFACT, XML, JSON, CSV, relational model, NoSQL). Transition to new technologies or the integration of information systems based on different technological stacks is a complex and expensive process. Platform-independent models take an important role in this process. The structure of such a model is described in this article. However, given the data model has been created at the junction of different domains, it may be not enough. In such case, a one more step of abstraction and a movement to the computation-independent model is required. The authors propose to create it in an ontological form.
DA  - 2015///
PY  - 2015
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Included"
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - An ontology-driven approach to electronic document structure design
AU  - Nikiforov, Denis A.
AU  - Korchagin, Alexander B.
AU  - Sivakov, Ruslan L.
AU  - Ignatov, Dmitry I.
AU  - Khachay, Mikhail Yu.
AU  - Labunets, Valeri G.
AU  - Loukachevitch, Natalia
AU  - Nikolenko, Sergey I.
AU  - Panchenko, Alexander
AU  - Savchenko, Andrey V.
AU  - Vorontsov, Konstantin
AB  - Over the course of history, humankind used documents as one of the ways of organization of the data. In the recent decades, electronic documentation became increasingly widespread. To make electronic documents exchange possible, standards regulating transmission protocols, representation formats, and rules for document building are necessary. For some protocols (HTTP, SOAP, etc.) and formats (EDI, XML, JSON, etc.), relatively fixed and generally accepted standards are available. As for the electronic document design, there is an abundance of approaches where a leader could hardly be established; all of them have their benefits and drawbacks. This study explores some of these approaches (UN/CEFACT CCTS, WCO DM, ISO 20022, and NIEM). These approaches have different features but from the conceptual perspective they are intended to describe sets of details of some real-world objects. The paper proposes to describe such objects using an ontology and then, based on this ontology, build conceptual structures of electronic documents that can be converted to platform-independent structures of electronic documents in accordance with one of the standards. The introduced approach allows harmonizing the standards under consideration.
DA  - 2017///
PY  - 2017
DO  - 10.1007/978-3-319-52920-2_1
SP  - 3
EP  - 16
SN  - 978-3-319-52920-2
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Maybe"
ER  -

TY  - JOUR
TI  - The b-terminal busy probability prediction
AU  - Poryazov, Stoyan
T2  - International Journal
AB  - In the teletraffic engineering of all the telecommunication networks, parameters characterizing the terminal traffic are used. One of the most important of them is the probability of finding the called (B-terminal) busy. This parameter is studied in some of the first and last papers in Teletraffic Theory. We propose a solution in this topic in the case of (virtual) channel systems, such as PSTN and GSM. We propose a detailed conceptual traffic model and, based on it, an analytical macro-state model of the system in stationary state, with: Bernoulli–Poisson–Pascal input flow; repeated calls; limited number of homogeneous terminals; losses due to abandoned and interrupted dialling, blocked and interrupted switching, not available intent terminal, blocked and abandoned ringing and abandoned conversation. Proposed in this paper approach may help in determination of many network traffic characteristics at session level, in performance evaluation of the next generation mobile networks.
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - RDFArM-a system for storing large sets of RDF triples and quadruples by means of natural language addressing
AU  - Ivanova, Krassimira
T2  - INFORMATION MODELS & ANALYSES
AB  - In this paper we present results from experiments for storing middle-size and large sets of RDF triples and quadruples by means of Natural Language Addressing. For experiments we have realized program RDFArM aimed to store RDF triples and quadruples in multi-layer hash tables (information spaces with variable size). The main features of program RDFArM are outlined in the paper. Analysis of the experimental results and rank-based multiple comparison are discussed.
DA  - 2012///
PY  - 2012
SP  - 303
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - ArmSquare: An association rule miner based on multidimensional numbered information spaces
AU  - MITOV, Iliya
AU  - IVANOVA, Krassimira
AU  - DEPAIRE, Benoit
AU  - VANHOOF, Koen
AB  - In this article, we propose a simple approach for association rule mining, which uses the possibilities of the multidimensional numbered information spaces as a storage structures. The main focus in the realization of ArmSquare is using the advantages of such spaces, i.e., the possibility to build growing space hierarchies of information elements, the great power for building interconnections between information elements stored in the information base, and the possibility to change searching with direct addressing in well structured tasks. The tested types of implementations of realized tool show the vividness of proposed approach.
DA  - 2011///
PY  - 2011
SP  - 143
EP  - 148
LA  - en
SN  - 978-1-61839-702-7
N1  - 1st International Conference on Advances in Information Mining and Management | RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
KW  - Association Rule Mining
KW  - Market Basket Analysis
KW  - Multidimensional Numbered Information Spaces
ER  -

TY  - JOUR
TI  - Increased efficiency in virtual commissioning with automated model generation based on component libraries
AU  - Pyschny, Nicolas
AU  - Rudat, Ben
AU  - Permin, Eike
T2  - Procedia CIRP
AB  - The use of Virtual Commissioning (VC) is becoming increasingly relevant for the engineering of automation systems. VC allows for validating concepts and design solutions in the early phases of product development, thereby improving communication among disciplines, reducing the costs for bug fixing and accelerating the overall engineering process, in particular the commissioning of plants and machines. However, as an additional software tool in engineering, the introduction of VC causes initial training and more importantly continuous extra modelling efforts. An approach to overcome this flaw is the automated generation of VC models based on existing engineering information from the system or domain level – ideally in tandem with the reuse of solution models from previous project. The latter can prove particularly beneficial in the context of modular building-block systems as often pursued in automation engineering.
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.procir.2022.05.258
VL  - 109
SP  - 328
EP  - 333
LA  - en
SN  - 22128271
UR  - https://linkinghub.elsevier.com/retrieve/pii/S2212827122007077
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
ER  -

TY  - JOUR
TI  - A survey of mathematical and informational foundations of the bigarm access method
AU  - Ivanova, Krassimira
T2  - International Journal
AB  - The BigArM is an access method for storing and accessing Big Data. It is under development. In this survey we present its mathematical and informational foundations as well as its requirements to realization characteristics. Firstly, we outline the needed basic mathematical concepts, the Names Sets, and hierarchies of named sets aimed to create a specialized model for organization of information bases called “Multi-Domain Information Model” (MDIM). The “Information Spaces” defined in the model are kind of strong hierarchies of enumerations (named sets). Further we remember the main features of hashing and types of hash tables as well as the idea of “Dynamic perfect hashing” and “Trie”, especially – the “Burst trie”. Hash tables and tries give very good starting point. The main problem is that they are designed as structures in the main memory which has limited size, especially in small desktop and laptop computers. To solve this problem, dynamic perfect hashing and burst tries will be realized as external memory structures in BigArM.
DA  - 2015///
PY  - 2015
VL  - 9
IS  - 3
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Multi-layer knowledge representation
AU  - Ivanova, Krassimira
T2  - International Journal “Information Content and Processing
AB  - An approach for knowledge representation based on post-relation type of information bases is outlined in the paper. Explanation starts with remembering the idea of Natural Language Addressing. After that, the idea of Multi-layer Knowledge Representation by Means of Natural Language Addressing is presented.
DA  - 2014///
PY  - 2014
VL  - 1
IS  - 4
SP  - 303
EP  - 310
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - OntoArM-a system for storing ontologies by natural language addressing
AU  - Ivanova, Krassimira
T2  - INFORMATION TECHNOLOGIES & KNOWLEDGE
AB  - In this paper we present results from experiments for storing RDF ontologies by means of Natural Language Addressing. For experiments we have realized system OntoArM aimed to store RDF triples in multilayer hash tables (information spaces with variable size). The main features of system OntoArM are outlined in the paper. Analysis of the experimental results concluded the work.
DA  - 2014///
PY  - 2014
SP  - 303
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Evaluating SPARQL-based model checking: Potentials and limitations
AU  - Hoffmann, A
AU  - Shi, M
AU  - Wagner, A
AU  - Thiele, C-D
AU  - Huyeng, T-J
AU  - Rüppel, U
AU  - Sprenger, W
T2  - ECPPM 2021-eWork and eBusiness in architecture, engineering and construction
AB  - Model checking is an important task in the BIM collaboration process to prevent expensive planning errors. The submodels of the individual disciplines are transferred into a coordination model. Part of the transfer is a conversion into an exchange format. The exchange format allows the import into the model checking application. In the model checking application routines are performed to check the model against collisions and building regulation violations. During the transfer into the exchange format, information may get lost, especially with parameters that are not yet part of the exchange format supported by the authoring software. In recent years, ontologies have been investigated as a feasible approach to combine the submodels, since they model data in a flexible manner. Hence in the conversion process to an application-specific ontology, the data structure of the submodels can widely persist, which could lead to smaller information loss in comparison to converting the data into a standardized exchange format. The evaluation of the geometric properties of the building is indispensable for detecting and analyzing collisions. The basis for the connection of the different sub models could be the BOT (Building Topology Ontology), which defines the topological structure of a building and can be used to represent further building information by linking it with other ontologies. The relevant geometric relationships for the collision model checks have to be derived with a geometry kernel. For the research in this paper pythonOCC, a wrapper for the geometry kernel Open CASCADE is used with the Semantic Web's own query language SPARQL, queries can be formulated to analyze the collision relationships in combination with other semantic information. These queries can be used to verify model correctness. By connecting the information from different domains, more sophisticated tests are possible than in an exchange format dependent model checking application. The goal is to integrate the developed functionalities into a project platform. This platform is based on an extensive project description in an ontology-based data model and is connected to different authoring tools for the exchange of information.
DA  - 2021///
PY  - 2021
DO  - 10.1201/9781003191476-11
SP  - 83
EP  - 90
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Included"
ER  -

TY  - JOUR
TI  - Storing and processing accounting information based on collect/report paradigm
AU  - Ivanova, Krassimira
T2  - International Journal
AB  - The possibility to store and process accounting information using the Collect/Report Paradigm (CRP) is outlined in this paper. The main idea consists of using CRP to distribute accounting information in multi-dimensional information spaces and stored and processed it in parallel in cloud. Every account may be presented by a separated layer which contains two named sets – Dr and Cr. Storing and reporting may be provided simultaneously without recompilation of the information base.
DA  - 2015///
PY  - 2015
VL  - 2
IS  - 2
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Building data warehouses using numbered information spaces
AU  - Markov, Krassimir
AB  - An approach for organizing the information in the data warehouses is presented in the paper. The possibilities of the numbered information spaces for building data warehouses are discussed. An application is outlined in the paper.
DA  - 2006///
PY  - 2006
SP  - 201
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Algorithm for quick numbering of large volumes of data
AU  - Ivanova, Krassimira
T2  - International Journal
AB  - An original algorithm for numbering large datasets by means of Natural Language Addressing (NLA) is presented in the paper. We use a counter to number different instances and store its current value in the container NL-addressed by the instance. If the instance is repeated, from this NL-address we receive its already assigned number. The algorithm is implemented in an experimental program RDFArM for storing large RDF-datasets. The provided experiments have shown that NL-access time for one instance (triple or quadruple) does not depend on number of already stored instances from the dataset. This is very important for storing Big Data.
DA  - 2015///
PY  - 2015
VL  - 22
IS  - 4
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Example of multi-layer knowledge representation by means of natural language addressing
AU  - Ivanova, Krassimira
T2  - ITHEA® Kyiv-Sofia, 2014
AB  - An approach for knowledge representation based on post-relation type of information bases is outlined in the paper. The idea of Natural Language Addressing and based on it idea of Multi-layer Knowledge Representation are presented.
DA  - 2014///
PY  - 2014
SP  - 115
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Managerial and ontological issues in the development of enterprise architecture: Experiences from a case study
AU  - Hedman, Jonas
AU  - Schonström, Mikael
AB  - With increasing numbers and complexity of information models, it is becoming more and more important to have supporting modeling frameworks. Previous literature within this field has been descriptive, conceptual, and normative with few empirical studies addressing managerial and cognitive challenges during the development of large-scale models. This article addresses modeling from three perspectives: Enterprise Architecture (EA), Ontology, and Management Theory. The article presents the experiences from a large corporation effort to develop a modeling framework. The focus is on managerial and cognitive issues related to the development and use of the modeling framework. The conclusion is that large-scale modeling activities are complex involving several cognitive issues, such as managing different interpretations of terms due to different languages, modeling frameworks, cultures, and information systems.
DA  - 2013///
PY  - 2013
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Included"
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Data independence in the multi-dimensional numbered information spaces
AU  - Markov, Krassimir
AB  - The concept of data independence designates the techniques that allow data to be changed without affecting the applications that process it. The different structures of the information bases require corresponded tools for supporting data independence. A kind of information bases (the Multi-dimensional Numbered Information Spaces) are pointed in the paper. The data independence in such information bases is discussed.
DA  - 2008///
PY  - 2008
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Multi-domain data modeling for biometrics
AU  - Chen, Alex
AU  - Kinser, Jason
AB  - Recently, much work has been performed on CBIR (content based image retrieval) that treats images as single data domain. However, in our highly digitized society, information is being supplied in multiple domains where the data is linked across domains. For example, a web site does contain images, but it may also contain text, hyperlinks, documents, sound files, movies, and other domains of data. Performing recall operations within single domains eliminates the possibility of employing cross-domain inferences. In this work, a multi-domain search space is presented in with two domains: speech and facial images. A single search space is created that contains data from these vastly different domains and cross-domain inferences are allowed. In other words, queries in the speech domain can retrieve image data even if there was no hard link between these data samples. Generation of multidomain search spaces will eventually expand CBIR systems to include data from a variety of sources.
DA  - 2011/10//
PY  - 2011
DO  - 10.1109/AIPR.2011.6176354
SP  - 1
EP  - 5
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Maybe"
KW  - Accuracy
KW  - Biometrics
KW  - Data domains
KW  - Data models
KW  - data query
KW  - Face
KW  - Image color analysis
KW  - IsoMap
KW  - Speech
KW  - Vectors
ER  -

TY  - JOUR
TI  - Decentralization in industry 4.0 supported by opc ua multi-domain information models: Case study and implementation challenges
AU  - Pribiš, Rudolf
AU  - Beňo, Lukáš
AU  - Pajpach, Martin
AU  - Drahoš, Peter
AU  - Kocák, Ondrej
AB  - This paper introduces an OPC UA multi-domain information model aimed at supporting decentralization in industrial automation and includes a case study addressing the implementation challenges associated with integrating standards such as Device, PackML, ISA95, and AAS. The developed model enables interoperability and harmonization of information models across various domains, which is crucial for Industry 4.0 applications. The work highlights the paradox of decentralization, where independent modules require centralized control and data coordination, necessitating a unified information model. Key contributions include the proposal of methods to address technical challenges related to data type compatibility and inheritance of properties across domains. Additionally, the text emphasizes the importance of system integration for data acquisition from physical assets. A comparative analysis of implementation on PLCs, on-premises computing platforms, and cloud environments highlights tradeoffs in deployment depending on system complexity and response time requirements. The study results may assist in developing an information model for a decentralized unit in Industry 4.0.
DA  - 2025/02//
PY  - 2025
DO  - 10.1109/KI64036.2025.10916421
SP  - 1
EP  - 6
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Maybe"
KW  - Computational modeling
KW  - Data models
KW  - decentralization
KW  - Fourth Industrial Revolution
KW  - Industry 4.0
KW  - Interoperability
KW  - multi-domain information model
KW  - OPC UA
KW  - Proposals
KW  - Servers
KW  - Standards
KW  - Synchronization
KW  - System integration
KW  - Time factors
ER  -

TY  - JOUR
TI  - About two stereotypes of uml profile for multidimensional numbered data bases
AU  - Chebanyuk, Olena
AU  - Ivanova, Krassimira
AU  - Velychko, Vitalii
AU  - Markov, Krassimir
T2  - Ministry of Education and Science of Ukraine National Aviation University Software Engineering Department
AB  - Two stereotypes for Numbered Space (NSpace) and Space with Natural Language Addressing (NLASpace) from an UML profile for modeling Multi-Dimensional Numbered Data Bases (MDNDB™) are shortly outlined in this paper. MDNDB™ is a tool for storing Big Data locally as well as in the cloud. Because of this, it is important to have appropriate modeling language to support the design of practical applications.
DA  - 2019///
PY  - 2019
SP  - 30
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - From concept to reality: a contemporary framework for virtual designing and commissioning processing plant systems
AU  - Nielsen, Mads Kjærgaard
AU  - Beliatis, Michail J.
AU  - Tambo, Torben
T2  - Procedia Computer Science
AB  - The design and commissioning of process systems involve complex procedures often guided by digital Mock-Ups, replacing physical prototypes. This study presents a comprehensive framework integrating Virtual Commissioning, 3D CAD modeling, and industry standards to enhance the design process of such systems, supporting first-time-right implementations. The methodology combines literature review, industry standards, and case studies from the feed processing industry. The framework emphasizes interoperability, data model integrity, simulation, and cross-disciplinary communication. Findings suggest a refined model structure for modern manufacturing complexities, with practical implications for industry practitioners. Future research should refine the framework and explore broader industrial applications, improving implementation processes.
DA  - 2025///
PY  - 2025
DO  - 10.1016/j.procs.2025.01.159
VL  - 253
SP  - 974
EP  - 984
LA  - en
SN  - 18770509
UR  - https://linkinghub.elsevier.com/retrieve/pii/S187705092500167X
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
ER  -

TY  - JOUR
TI  - Big data addressed in natural language
AU  - Markova, Vera
AU  - Ivanova, Krasimira
AU  - Karastanev, Stefan
AB  - Actions related to the cloud processing of large volumes of semi- or unstructured, streaming data (so-called “Big Data”) pose challenges that organizations must address. They are related to the location of the data in the cloud, its storage and management. Much of Big Data is collected from sources that are external to the business organization, such as social media, demographics, web data, events, news sources, and more. In this article, we discuss an access method to enable support for very large Big Data databases. It is based on the capabilities of Natural Language Addressing (NLA). An important advantage of NLA is the reduction of the amount of occupied memory due to the complete absence of additional indexes, absolute addresses, pointers and additional files, as well as the reduction of processing time due to the complete absence of searches - data is stored / retrieved to / from a direct address.
DA  - 2023/12//
PY  - 2023
DO  - 10.1109/AEIS61544.2023.00016
SP  - 53
EP  - 57
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - Big Data
KW  - big data databases
KW  - BigNLA access method
KW  - Data models
KW  - Memory management
KW  - natural language addressing
KW  - Natural languages
KW  - Organizations
KW  - Social networking (online)
KW  - Task analysis
ER  -

TY  - JOUR
TI  - Building data warehouses using numbered information spaces
AU  - Mostovoi, Sergey V
T2  - International Journal
AB  - An approach for organizing the information in the data warehouses is presented in the paper. The possibilities of the numbered information spaces for building data warehouses are discussed. An application is outlined in the paper.
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Distributed virtual laboratories for smart sensor system design
AU  - Palagin, Oleksandr
AU  - Romanov, Volodymyr
AU  - Velychko, Vitalii
AU  - Galelyuka, Igor
AU  - Fedak, Volodymyr
AU  - Grusha, Volodymyr
AU  - Artemenko, Dmytro
AU  - Galelyuka, Oksana
T2  - INFORMATION TECHNOLOGIES & KNOWLEDGE
AB  - In the article it is considered preconditions and main principles of creation of virtual laboratories for computer-aided design, as tools for interdisciplinary researches. An important feature of this project is using the advanced multi-dimensional access method for organizing the information base of the Virtual laboratory. Virtual laboratory, what are offered, is worth to be used on the stage of the requirements specification or EFT-stage, because it gives the possibility of fast estimating of the project realization, certain characteristics and, as a result, expected benefit of its applications. Using of these technologies already increase automation level of design stages of new devices for different purposes. Proposed computer technology gives possibility to specialists from such scientific fields, as chemistry, biology, biochemistry, physics etc, to check possibility of device creating on the basis of developed sensors. It lets to reduce terms and costs of designing of computer devices and systems on the early stages of designing, for example on the stage of requirements specification or EFT-stage. An instance of using the VLCAD is designing the Portable Device" Floratest" as Tool for Estimating of Megalopolis Ecology State. Portable device" Floratest" is aimed for express-diagnostic of plant state. It is developed in the VM Glushkov Institute of Cybernetics of National Academy of Sciences of Ukraine. Party of this device is manufactured and transferred to organizations, worked in the agricultural sector, environmental protection area, mineral fertilizer production etc. for working out of methodical tools. Using of the device for estimating of megalopolis ecology state by means of evaluation of green plant state is described in the article. Together with Megalopolis Ecomonitoring and Biodiversity Research Center of National Academy of Sciences of Ukraine there were got results of experimental researches of influence detecting of heavy metals and harmful substances on the trees and plants in Kiev.
DA  - 2009///
PY  - 2009
SP  - 364
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Industrial digitally prototypes
AU  - Niemann, Jörg
AU  - Pisla, Adrian
AU  - Niemann, Jörg
AU  - Pisla, Adrian
T2  - Life-Cycle Management of Machines and Mechanisms
AB  - The whole product lifetime can be firstly defined into 5 major phases.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-56449-0_17
SP  - 323
EP  - 353
SN  - 978-3-030-56449-0
UR  - https://doi.org/10.1007/978-3-030-56449-0_17
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
ER  -

TY  - JOUR
TI  - Automatic metadata generation and digital cultural heritage
AU  - Mitov, Iliya
AU  - Depaire, Benoit
AU  - Ivanova, Krassimira
AU  - Vanhoof, Koen
AU  - Blagoev, Dimitar
DA  - 2012///
PY  - 2012
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -

TY  - JOUR
TI  - Multi-variant pyramidal clustering and analysis high-dimensional data
AU  - Ivanova, Krassimira B
AU  - Velychko, Vitalii
AU  - Markov, Krassimir
T2  - International Journal
AB  - In this work an example of multi-variant clustering is presented. The problems to be solved are described and multi-variant clustering based on pyramidal multi-layer multi-dimensional structures is outlined. The conclusion is that the multi-variant clustering combined with pyramidal generalization and pruning gives reliable results.
DA  - 2012///
PY  - 2012
VL  - 19
IS  - 1
LA  - en
N1  - RAYYAN-INCLUSION: "Arjen"=¿"Excluded" | RAYYAN-EXCLUSION-REASONS: not relevant
KW  - ⛔ No DOI found
ER  -
