,type_of_reference,title,authors,abstract,date,year,issn,secondary_title,start_page,end_page,publisher,custom3,doi,keywords,language,type_of_work,place_published,secondary_authors,custom1,notes,urls,database_provider,volume,number,alternate_title1,short_title,access_date,file_attachments2,tertiary_authors,asreview_label,asreview_time,asreview_note
51,JOUR,Semantic interoperability in eGovernment initiatives,"['Guijarro, Luis']","Interoperability has been identified as a major issue to be addressed by every egovernment initiatives. In order to tackle this issue, the egovernment agencies have developed tools to facilitate the interchange of information between departments when providing public services to citizens and businesses through internet. This paper surveys how the egovernment agencies in Europe and the United States have developed tools such as interoperability frameworks and enterprise architectures. It covers specifically how the semantic technologies and standards have been incorporated into the interoperability frameworks. The incorporation is a sign of maturity, because interoperability is to cover not only technical aspects, but also semantic and, in the end, organisational aspects.",2009/01//,2009,09205489,Computer Standards & Interfaces,174,180,,,10.1016/j.csi.2007.11.011,,en,,,,,[],['https://linkinghub.elsevier.com/retrieve/pii/S0920548907001274'],DOI.org (Crossref),31,1,Computer Standards & Interfaces,,2025/10/04/14:38:43,,,1,2025-10-04 14:53:16,
37,CONF,An Ontology for e-Government Knowledge Modeling and Interoperability,"['Xiao, Yi', 'Xiao, Ming', 'Zhao, Hui']","In order to meet the demand of exchange, share and reuse business knowledge among the different government institutions in e-government, an ontology-based approach to modeling and collaborating e-government business knowledge was proposed. An e-Government Business Ontology (EGBOnt) was designed. The model of EG-BOnt was described by the IDEF5 graphically. Then the precise syntax and formal semantics of EG-BOnt were defined by OWL language because of its stronger semantics and logic relation expressiveness. Finally, the architecture of e-government knowledge collaboration management platform based on EGBOnt was presented. This approach accelerates a common understanding of relevant business knowledge and provides a new research direction about implement the interoperation of the heterogeneous government institutions in e-government. It will be helpful to improve the efficiency and quality of egovernment services and promote the realization of one-stop e-government.",2007/09//,2007,978-1-4244-1311-9 978-1-4244-1312-6,"2007 International Conference on Wireless Communications, Networking and Mobile Computing",3600,3603,IEEE,"2007 International Conference on Wireless Communications, Networking and Mobile Computing",10.1109/WICOM.2007.891,,en,,,,"Shanghai, China",[],['http://ieeexplore.ieee.org/document/4340666/'],DOI.org (Crossref),,,,,2025/10/04/14:38:21,,,1,2025-10-04 14:53:43,
25,JOUR,Semantic E-government Portals – A Case Study,"['Sidoroﬀ, Teemu', 'Hyvonen, Eero']","This paper presents a case study on how semantic search and browsing techniques can be applied to solving the problems of content discovery, aggregation, and linking in e-government portals. At the same time, adaptability of a semantic portal tool, OntoViews, based on the multi-facet search paradigm, to diﬀerent kinds of content was tested. Our conclusion is that representing content and their linking in terms of semantic web ontologies and logic rules is ﬂexible from the system construction viewpoint, can be used to provide the end-user with useful “semantic” services, and can reduce human eﬀort in portal maintenance.",,,,,,,,,,['⛔ No DOI found'],en,,,,,[],,Zotero,,,,,,,,1,2025-10-04 14:55:51,
45,CONF,A new semantic knowledge sharing approach for e-government systems,"['Miah, Shah Jahan']","Knowledge sharing within a large entity such as government organizations, is critical to successful e-government implementations. Semantic technologies offer promise in this regard, however, many studies in the past have suggested that the semantic technologies for knowledge sharing suffer from potential weaknesses such as dynamicity, scalability, flexibility and offer limited options for specific business applications. In most cases the need for knowledge integration in business interactions in government systems are overlooked or loosely addressed due to rapidly changing situations and complex business networking. Significant challenges remain in developing e-government solution that can address the need for growing knowledge integration and sharing to enhance business interactions. This paper outlines a knowledge sharing framework to solve these issues with respect to citizen’s participation in egovernment system, by encouraging user driven activities through the use of emerging technology and ontology based design.",2010/04//,2010,978-1-4244-5551-5,2010 4th IEEE International Conference on Digital Ecosystems and Technologies (DEST),457,462,IEEE,4th IEEE International Conference on Digital Ecosystems and Technologies,10.1109/DEST.2010.5610607,,en,,,,"Dubai, United Arab Emirates",[],['http://ieeexplore.ieee.org/document/5610607/'],DOI.org (Crossref),,,,,2025/10/04/14:38:33,,,1,2025-10-19 19:58:57,
53,JOUR,Semantic Interoperability Architecture for Electronic Government,"['Ojo, Adegboyega', 'Janowski, Tomasz', 'Estevez, Elsa']","Semantic Interoperability is arguably the least developed aspect of Government Interoperability Frameworks. This could be explained by poor understanding of the semantic interoperability problem in government, considering its substance and scope, difficulties encountered in aligning technical solutions with the practice of government organizations, and the paucity of mature semantic technologies and complete semantic interoperability architectures and solutions (beyond metadata specification and semantic annotation of resources). As a result, most governments prefer to concentrate on technical and organizational aspects of their information sharing and interoperability efforts.",,,,,,,,,,['⛔ No DOI found'],en,,,,,[],,Zotero,,,,,,,,1,2025-10-19 19:59:11,
35,JOUR,Data-GovWiki: Towards Linking Government Data,"['Ding, Li', 'Difranzo, Dominic', 'Graves, Alvaro', 'Michaelis, James R', 'Li, Xian', 'McGuinness, Deborah L', 'Hendler, Jim']","Data.gov is a website that provides US Government data to the general public to ensure better accountability and transparency. Our recent work on the Data-gov Wiki, which attempts to integrate the datasets published at Data.gov into the Linking Open Data (LOD) cloud (yielding ”linked government data”), has produced 5 billion triples covering a range of topics including: government spending, environmental records, and statistics on the cost and usage of public services. In this paper, we investigate the role of Semantic Web technologies in converting, enhancing and using linked government data. In particular, we show how government data can be (i) inter-linked by sharing the same terms and URIs, (ii) linked to existing data sources ranging from the LOD cloud (e.g. DBpedia) to the conventional web (e.g. the New York Times), and (iii) cross-linked by their knowledge provenance (which captures, among other things, derivation and revision histories).",,,,,,,,,,['⛔ No DOI found'],en,,,,,[],,Zotero,,,,,,,,1,2025-10-19 20:00:04,
54,JOUR,Towards a Semantic Interoperability in an e-Government Application,"['Bettahar, Fathia', 'Moulin, Claude', 'Barthès, Jean-Paul']","Research issues have emerged from the rapid introduction of new technologies in government services in order to deliver efficient and cost effective services, information and knowledge through information and communication technologies. However, the complexity of government services and the diversity of actors involved in the processes make the access to the right information difficult and pose several problems. Some problems are linked to the way of presenting and accessing information. Other problems are linked to interoperability among applications and processes of eGovernment services. The objective of the European TerreGov project is to find a solution to such problems. The project focuses on the semantic requirements of governments at local, intermediate and regional levels, needed to build flexible and interoperable tools to support the change towards eGovernment services. We propose, within this project, an ontology to present knowledge and to achieve the required level of semantic interoperability. We use the ontology to describe the domain knowledge of the organization and to index the resources from which civil servants may receive information. The key point of the system is a unique and multimodal ontology used simultaneously for describing domain knowledge, for adding semantics to agency services, for indexing various documents in knowledge bases used by civil servants and finally for supporting the interaction between the users and the system. We present in this paper the challenges of using ontology in eGovernment environments, such as the lack of expressivity of the formalism chosen for interoperability in the project and the risk of inconsistency when the ontology changes. We propose our solution to such challenges and we demonstrate the use of the ontology by the module in charge of managing complex tasks in the system.",2009///,2009,,,,,,,,,en,,,,,[],,Zotero,7,3,,,,,,1,2025-10-19 20:01:29,
41,JOUR,The Semantic Electronic Government: knowledge management for citizen relationship and new assessment scenarios,"['Lytras, Miltiadis D.']","The case of governance in the internet age requires a critical revision of assumptions. Government and citizens are not just two entities but through their interaction provide a wide context of analysis. Citizen Relationship Management (CRM) is a knowledge-intensive task, which requires an in-depth analysis of knowledge infrastructures, knowledge flows and dynamic transformations. In this paper, we will concentrate on the description of the basic aspects of the Knowledge Management (KM) convergence in e-government. Further, the diversity of structures, regulations and procedures affecting networks of heterogeneous administrative units represents a challenge for semantic integration. Semantic Web technologies have been proposed as a potential solution for alleviating such integration problems. However, Semantic Web initiatives must be based on clear and realistic objectives that can be assessed in the framework of political decisions. This paper attempts to delineate the main aspects of a framework for assessment, in an attempt to delineate a roadmap for future applied research on the area.",2006///,2006,"1740-7494, 1740-7508","Electronic Government, an International Journal",5,,,,10.1504/EG.2006.008489,,en,,,,,[],['http://www.inderscience.com/link.php?id=8489'],DOI.org (Crossref),3,1,EG,The Semantic Electronic Government,2025/10/04/14:38:27,,,1,2025-10-19 20:02:07,
24,JOUR,"A State-of-the-Art Analysis of the Current Public Data Landscape from a Functional, Semantic and Technical Perspective","['Petychakis, Michael', 'Vasileiou, Olga', 'Georgis, Charilaos', 'Mouzakitis, Spiros', 'Psarras, John']","Open Government Data initiatives and particularly Open Government Data portals have proliferated since the late 2000’s. A comprehensive analysis of the capabilities and potential of these initiatives is currently missing from the recent research literature. In order to address this gap, the paper at hand aims towards analyzing the landscape of Open Governmental Data in the European Union from a functional, semantic and technical perspective. Our research focused on the collection and categorization of an indicative number of public data sources for each of the 27 European Union country-members through investigating their services and characteristics. By modeling and classifying the data sources according to their key attributes, we were able to proceed to their statistical analysis and assessment in terms of their content, licensing, multilingual support, acquisition, ease of access, provision and data format. Our results portray the current quality of Public Sector Information infrastructures and highlight what still needs to be done in order to make public data truly open and readily available for researchers, citizens, companies and innovation in general.",2014/08//,2014,0718-1876,Journal of theoretical and applied electronic commerce research,7,8,,,10.4067/S0718-18762014000200004,,en,,,,,[],['http://www.scielo.cl/scielo.php?script=sci_arttext&pid=S0718-18762014000200004&lng=en&nrm=iso&tlng=en'],DOI.org (Crossref),9,2,J. theor. appl. electron. commer. res.,,2025/10/04/14:38:01,,,1,2025-10-19 20:03:20,
17,JOUR,Knowledge management for Government-to-Government (G2G) process coordination,"['Iyer, Lakshmi S.', 'Singh, Rahul', 'Salam, Al F.', ""D'Aubeterre, Fergle""]","E-government is gaining momentum and has firmly established itself in addition to common terms such as ‘e-commerce’ or ‘e-business’. Given that e-government services extend across different organisational boundaries and heterogeneous infrastructures, there is a critical need to manage the knowledge and information resources stored in these disparate systems. Semantic Web technologies have the potential to manage the knowledge and coordinate Government-to-Government (G2G) processes. Based on the foundations of Semantic Web, including ontologies, knowledge representation, multi-agent systems and web services; Knowledge Management (KM) and G2G processes, we present a vision for KM for G2G process coordination. The Semantic G2G integration can support the transparent flow of semantically enriched information and knowledge, including content and know-how and enable collaborative G2G processes within and across governmental agencies.",2006///,2006,"1740-7494, 1740-7508","Electronic Government, an International Journal",18,,,,10.1504/EG.2006.008490,,en,,,,,[],['http://www.inderscience.com/link.php?id=8490'],DOI.org (Crossref),3,1,EG,,2025/10/04/14:37:11,,,1,2025-10-19 20:03:41,
40,CONF,DIGO: An Open Data Architecture for e-Government,"['Machado, Alexandre Lopes', 'Parente De Oliveira, Jose Maria']","Currently most governing bodies publish their data on the World Wide Web (WWW). These data are available on e-Government Web Portals in unstructured formats using current Web languages, making them difﬁcult to reuse and to generate new information. In this context, access to relevant, accurate public information, and possible reuse by other applications become increasingly complex. Open Government Data (OGD) means the publication of data in open raw formats (open data). There are tools to put open data on the WWW. However, this tools doesn’t work with an architecture covering all aspects of data reuse. The aim of this paper is to show an architecture called Delivering Information of GOvernment (DIGO) to allow access to primary data by machines in open data so that citizens interested in doing so can combine them (linked open data) and produce new information and mashup applications, consequently, enabling OGD and data fusion on the Linking Open Data (LOD) cloud.",2011/08//,2011,978-1-4577-0869-5 978-0-7695-4426-7,2011 15th IEEE International Enterprise Distributed Object Computing Conference Workshops,448,456,IEEE,2011 IEEE 15th International Enterprise Distributed Object Computing Conference Workshops,10.1109/EDOCW.2011.34,,en,,,,Helsinki,[],['https://ieeexplore.ieee.org/document/6037649/'],DOI.org (Crossref),,,,DIGO,2025/10/04/14:38:25,,,1,2025-10-19 20:04:47,
34,JOUR,"Charting Past, Present, and Future Research in the Semantic Web and Interoperability","['Rejeb, Abderahman', 'Keogh, John G.', 'Martindale, Wayne', 'Dooley, Damion', 'Smart, Edward', 'Simske, Steven', 'Wamba, Samuel Fosso', 'Breslin, John G.', 'Bandara, Kosala Yapa', 'Thakur, Subhasis', 'Liu, Kelly', 'Crowley, Bridgette', 'Desaraju, Sowmya', 'Ospina, Angela', 'Bradau, Horia']","Huge advances in peer-to-peer systems and attempts to develop the semantic web have revealed a critical issue in information systems across multiple domains: the absence of semantic interoperability. Today, businesses operating in a digital environment require increased supplychain automation, interoperability, and data governance. While research on the semantic web and interoperability has recently received much attention, a dearth of studies investigates the relationship between these two concepts in depth. To address this knowledge gap, the objective of this study is to conduct a review and bibliometric analysis of 3511 Scopus-registered papers on the semantic web and interoperability published over the past two decades. In addition, the publications were analyzed using a variety of bibliometric indicators, such as publication year, journal, authors, countries, and institutions. Keyword co-occurrence and co-citation networks were utilized to identify the primary research hotspots and group the relevant literature. The ﬁndings of the review and bibliometric analysis indicate the dominance of conference papers as a means of disseminating knowledge and the substantial contribution of developed nations to the semantic web ﬁeld. In addition, the keyword co-occurrence network analysis reveals a signiﬁcant emphasis on semantic web languages, sensors and computing, graphs and models, and linking and integration techniques. Based on the co-citation clustering, the Internet of Things, semantic web services, ontology mapping, building information modeling, bioinformatics, education and e-learning, and semantic web languages were identiﬁed as the primary themes contributing to the ﬂow of knowledge and the growth of the semantic web and interoperability ﬁeld. Overall, this review substantially contributes to the literature and increases scholars’ and practitioners’ awareness of the current knowledge composition and future research directions of the semantic web ﬁeld.",2022/05/25/,2022,1999-5903,Future Internet,161,,,,10.3390/fi14060161,,en,,,,,[],['https://www.mdpi.com/1999-5903/14/6/161'],DOI.org (Crossref),14,6,Future Internet,,2025/10/04/14:38:17,,,1,2025-10-19 20:06:05,
32,CONF,On publishing linked open government data,"['Kalampokis, Evangelos', 'Tambouris, Efthimios', 'Tarabanis, Konstantinos']","In the last years, a number of government led initiatives have been launched worldwide aiming at making government data freely available to everyone, without limiting restrictions. Linked Data has been employed by some of these as a paradigm that allows for the provision of structured, semantically enabled and linkable data on the Web. The objective of this article is to discuss how Linked Data has been used in government data provision so far and to describe an architecture that will enable the provision of integrated government data around real-world things in a decentralized manner. Moreover, an implementation of the specific architecture is described in detail employing a hypothetical use case scenario that involves real world public agencies and schools. This implementation includes among others the publishing of Linked Data on top of a relational database and inline the HTML code of a web page as well as the linking of data from distributed sources at the instance level.",2013/09/19/,2013,978-1-4503-1969-0,PCI 2013: 17th Panhellenic Conference on Informatics,25,32,ACM,Proceedings of the 17th Panhellenic Conference on Informatics,10.1145/2491845.2491869,,en,,,,Thessaloniki Greece,[],['https://dl.acm.org/doi/10.1145/2491845.2491869'],DOI.org (Crossref),,,,,2025/10/04/14:38:14,,,1,2025-10-19 20:06:42,
21,JOUR,Semantic Web for the Legal Domain: The next step,"['Casanovas, Pompeu', 'Palmirani, Monica', 'Peroni, Silvio', 'Van Engers, Tom', 'Vitali, Fabio']","Ontology-driven systems with reasoning capabilities in the legal ﬁeld are now better understood. Legal concepts are not discrete, but make up a dynamic continuum between common sense terms, speciﬁc technical use, and professional knowledge, in an evolving institutional reality. Thus, the tension between a plural understanding of regulations and a more general understanding of law is bringing into view a new landscape in which general legal frameworks – grounded in well-known legal theories stemming from 20th-century c. legal positivism or sociological jurisprudence – are made compatible with speciﬁc forms of rights management on the Web. In this sense, Semantic Web tools are not only being designed for information retrieval, classiﬁcation, clustering, and knowledge management. They can also be understood as regulatory tools, i.e. as components of the contemporary legal architecture, to be used by multiple stakeholders – front-line practitioners, policymakers, legal drafters, companies, market agents, and citizens. That is the issue broadly addressed in this Special Issue on the Semantic Web for the Legal Domain, overviewing the work carried out over the last ﬁfteen years, and seeking to foster new research in this ﬁeld, beyond the state of the art.",2016/03/23/,2016,"22104968, 15700844",Semantic Web,213,227,,,10.3233/SW-160224,,en,,,"['Casanovas, Pompeu', 'Palmirani, Monica', 'Peroni, Silvio', 'Van Engers, Tom', 'Vitali, Fabio']",,[],['https://journals.sagepub.com/doi/full/10.3233/SW-160224'],DOI.org (Crossref),7,3,SW,Semantic Web for the Legal Domain,2025/10/04/14:37:57,,,1,2025-10-19 20:08:46,
20,JOUR,Large-scale Semantic Integration of Linked Data: A Survey,"['Mountantonakis, Michalis', 'Tzitzikas, Yannis']","A large number of published datasets (or sources) that follow Linked Data principles is currently available and this number grows rapidly. However, the major target of Linked Data, i.e., linking and integration, is not easy to achieve. In general, information integration is difficult, because (a) datasets are produced, kept, or managed by different organizations using different models, schemas, or formats, (b) the same real-world entities or relationships are referred with different URIs or names and in different natural languages,<?brk?>(c) datasets usually contain complementary information, (d) datasets can contain data that are erroneous, out-of-date, or conflicting, (e) datasets even about the same domain may follow different conceptualizations of the domain, (f) everything can change (e.g., schemas, data) as time passes. This article surveys the work that has been done in the area of Linked Data integration, it identifies the main actors and use cases, it analyzes and factorizes the integration process according to various dimensions, and it discusses the methods that are used in each step. Emphasis is given on methods that can be used for integrating several datasets. Based on this analysis, the article concludes with directions that are worth further research.",2020/09/30/,2020,"0360-0300, 1557-7341",ACM Computing Surveys,1,40,,,10.1145/3345551,,en,,,,,[],['https://dl.acm.org/doi/10.1145/3345551'],DOI.org (Crossref),52,5,ACM Comput. Surv.,Large-scale Semantic Integration of Linked Data,2025/10/04/14:37:56,,,1,2025-10-19 20:09:34,
43,CHAP,Unlocking the Potential of Public Sector Information with Semantic Web Technology,"['Alani, Harith', 'Dupplaw, David', 'Sheridan, John', 'O’Hara, Kieron', 'Darlington, John', 'Shadbolt, Nigel', 'Tullo, Carol']","Governments often hold very rich data and whilst much of this information is published and available for re-use by others, it is often trapped by poor data structures, locked up in legacy data formats or in fragmented databases. One of the great beneﬁts that Semantic Web (SW) technology offers is facilitating the large scale integration and sharing of distributed data sources. At the heart of information policy in the UK, the Ofﬁce of Public Sector Information (OPSI) is the part of the UK government charged with enabling the greater re-use of public sector information. This paper describes the actions, ﬁndings, and lessons learnt from a pilot study, involving several parts of government and the public sector. The aim was to show to government how they can adopt SW technology for the dissemination, sharing and use of its data.",2007///,2007,978-3-540-76297-3 978-3-540-76298-0,The Semantic Web,708,721,Springer Berlin Heidelberg,,,,en,,"Berlin, Heidelberg","['Aberer, Karl', 'Choi, Key-Sun', 'Noy, Natasha', 'Allemang, Dean', 'Lee, Kyung-Il', 'Nixon, Lyndon', 'Golbeck, Jennifer', 'Mika, Peter', 'Maynard, Diana', 'Mizoguchi, Riichiro', 'Schreiber, Guus', 'Cudré-Mauroux, Philippe']",,[],['http://link.springer.com/10.1007/978-3-540-76298-0_51'],DOI.org (Crossref),4825,,,,2025/10/04/14:38:30,,"['Hutchison, David', 'Kanade, Takeo', 'Kittler, Josef', 'Kleinberg, Jon M.', 'Mattern, Friedemann', 'Mitchell, John C.', 'Naor, Moni', 'Nierstrasz, Oscar', 'Pandu Rangan, C.', 'Steffen, Bernhard', 'Sudan, Madhu', 'Terzopoulos, Demetri', 'Tygar, Doug', 'Vardi, Moshe Y.', 'Weikum, Gerhard']",1,2025-10-19 20:17:02,
23,JOUR,DESIGNING SEMANTIC E-GOVERNMENT SERVICES DRIVEN BY USER REQUIREMENTS,"['Klischewski, Ralf', 'Ukena, Stefan']","Designing the semantic structures for annotating e-government services is a critical challenge for administrations on the way to enter the Semantic Web. This article outlines a requirement-driven design approach that draws on information architecture and information quality concepts in relation to users’ informational needs. We suggest a step-by-step design process that alerts the administrations to focus on the intended common understanding of citizens or businesses and administrations concerning the description of the service “interface,” to analyze information demand and quality requirements for providing this description, and to determine the topics, terms and relations to be used for the description in order to fulfill these requirements. We claim that this design approach opens up the possibility for large-scale involvement of administrations and provides a crucial point of interception through defining informational requirements and thus creating benchmarks for subsequent activities in design and implementation.",,,,,,,,,,['⛔ No DOI found'],en,,,,,[],,Zotero,,,,,,,,1,2025-10-19 20:18:19,
18,JOUR,Developing a government enterprise architecture framework to support the requirements of big and open linked data with the use of cloud computing,"['Lnenicka, Martin', 'Komarkova, Jitka']","Governmental and local authorities are facing many new information and communication technologies challenges. The amount of data is rapidly increasing. The data sets are published in different formats. New services are based on linking and processing differently structured data from various sources. Users expect openness of public data, fast processing, and intuitive visualisation. The article addresses the challenges and proposes a new government enterprise architecture framework. The following partial architectures are included: big and open linked data storage, processing, and publishing using cloud computing. At first, the key concepts are defined. Next, the basic architectural roles and components are specified. The components result from the decomposition of related frameworks. The main part of the article deals with the detailed proposal of the architecture framework and partial views on architecture (sub-architectures). A methodology, including a proposal of appropriate steps, solutions and responsibilities for them, is described in the next step - after the verification and validation of the new framework with respect to the attributes of quality. The new framework responds to emerging ICT trends in order to evolve government enterprise architecture continually and represent current architectural components and their relationships.",2019/06//,2019,02684012,International Journal of Information Management,124,141,,,10.1016/j.ijinfomgt.2018.12.003,,en,,,,,[],['https://linkinghub.elsevier.com/retrieve/pii/S0268401218305942'],DOI.org (Crossref),46,,International Journal of Information Management,,2025/10/04/14:37:12,,,1,2025-10-19 20:19:03,
52,JOUR,Semantic integration of government data for water quality management,"['Chen, Zhiyuan', 'Gangopadhyay, Arrya', 'Holden, Stephen H.', 'Karabatis, George', 'McGuire, Michael P.']","Normative models of e-government typically assert that horizontal (i.e., inter-agency) and vertical (i.e., inter-governmental) integration of data flows and business processes represent the most sophisticated form of e-government, delivering the greatest payoff for both governments and users. This paper concentrates on the integration of data supporting water quality management as an example of how such integration can enable higher levels of e-government. It describes a prototype system that allows users to integrate water monitoring data across many federal, state, and local government organizations and provides novel techniques for information discovery, thus improving information quality and availability for decision making. Specifically, this paper outlines techniques to integrate numerous water quality monitoring data sources, to resolve data disparities, and to retrieve data using semantic relationships among data sources taking advantage of customized user profiles. Preliminary user feedback indicates that these techniques enhance quantity and quality of information available for water quality management.",2007/10//,2007,0740624X,Government Information Quarterly,716,735,,,10.1016/j.giq.2007.04.004,,en,,,,,[],['https://linkinghub.elsevier.com/retrieve/pii/S0740624X07000342'],DOI.org (Crossref),24,4,Government Information Quarterly,,2025/10/04/14:38:44,,,1,2025-10-19 20:19:35,
50,CHAP,Semantic Web for e-Government,"['Klischewski, Ralf']","As the e-government domain is about to become a field of application for Semantic Web technologies, the actors involved still lack reasoning to decide on critical issues such as organisational cost/benefit, „user“ involvement, technical integration, and implementation strategy. Firstly, the paper seeks to identify “semantic problems” in e-government as prerequisite for discussing the requirements for the application of Semantic Web technologies. Secondly, experiences from an ongoing project are discussed to identify critical issues from the systems development perspective. Thirdly, taking into account the problems identified and the case findings, a research agenda is laid out aiming to guide and support the application of Semantic Web technologies in e-government.",2003///,2003,978-3-540-40845-1 978-3-540-45239-3,Electronic Government,288,295,Springer Berlin Heidelberg,,,,en,,"Berlin, Heidelberg","['Traunmüller, Roland']",,[],['http://link.springer.com/10.1007/10929179_52'],DOI.org (Crossref),2739,,,,2025/10/04/14:38:42,,"['Goos, Gerhard', 'Hartmanis, Juris', 'Van Leeuwen, Jan']",1,2025-10-19 20:20:37,
26,CHAP,Enabling Interoperability of Government Data Catalogues,"['Maali, Fadi', 'Cyganiak, Richard', 'Peristeras, Vassilios']","Opening public sector information has recently become a trend in many countries around the world. Online government data catalogues with national, regional or local scope act as one-stop data portals providing descriptions of available government datasets. These catalogues though remain isolated. Potential beneﬁts from federating geographically overlapping or thematically complementary catalogues are not realized. We propose an RDF Schema vocabulary as an interchange format among data catalogues and as a way of bringing them into the Web of Linked Data, where they can enjoy interoperability among themselves and with other deployed datasets. The vocabulary’s design was informed by a survey of seven data catalogues from ﬁve diﬀerent countries, and has been veriﬁed by unifying four data catalogues to allow cross-catalogue queries and browsing.",2010///,2010,978-3-642-14798-2 978-3-642-14799-9,Electronic Government,339,350,Springer Berlin Heidelberg,,,,en,,"Berlin, Heidelberg","['Wimmer, Maria A.', 'Chappelet, Jean-Loup', 'Janssen, Marijn', 'Scholl, Hans J.']",,[],['http://link.springer.com/10.1007/978-3-642-14799-9_29'],DOI.org (Crossref),6228,,,,2025/10/04/14:38:04,,,1,2025-10-19 20:21:14,
46,JOUR,Combining Ontology Development Methodologies and Semantic Web Platforms for E-government Domain Ontology Development,"['Fonou Dombeu, Jean Vincent', 'Huisman, Magda']","One of the key challenges in electronic government (e-government) is the development of systems that can be easily integrated and interoperated to provide seamless services delivery to citizens. In recent years, Semantic Web technologies based on ontology have emerged as promising solutions to the above engineering problems. However, current research practicing semantic development in e-government does not focus on the application of available methodologies and platforms for developing government domain ontologies. Furthermore, only a few of these researches provide detailed guidelines for developing semantic ontology models from a government service domain. This research presents a case study combining an ontology building methodology and two state-of-the-art Semantic Web platforms namely Protégé and Java Jena ontology API for semantic ontology development in e-government. Firstly, a framework adopted from the Uschold and King ontology building methodology is employed to build a domain ontology describing the semantic content of a government service domain. Thereafter, UML is used to semi-formally represent the domain ontology. Finally, Protégé and Jena API are employed to create the Web Ontology Language (OWL) and Resource Description Framework (RDF) representations of the domain ontology respectively to enable its computer processing. The study aims at: (1) providing egovernment developers, particularly those from the developing world with detailed guidelines for practicing semantic content development in their e-government projects and (2), strengthening the adoption of semantic technologies in e-government. The study would also be of interest to novice Semantic Web developers who might used it as a starting point for further investigations.",2011/04/30/,2011,09762280,International journal of Web & Semantic Technology,12,25,,,10.5121/ijwest.2011.2202,,en,,,,,[],['http://www.airccse.org/journal/ijwest/papers/2211ijwest02.pdf'],DOI.org (Crossref),2,2,IJWesT,,2025/10/04/14:38:35,,,1,2025-10-19 20:22:01,
19,JOUR,The Emerging Web of Linked Data,"['Bizer, Christian']",,,,,,,,,,10.1109/MIS.2009.102,,en,,,,,[],,Zotero,,,,,,,,1,2025-10-19 20:22:13,No Abstract
42,JOUR,Using ontologies to improve semantic interoperability in health data,"['Liyanage, Harshana', 'Krause, Paul', 'De Lusignan, Simon']","The present–day health data ecosystem comprises a wide array of complex heterogeneous data sources. A wide range of clinical, health care, social and other clinically relevant information are stored in these data sources. These data exist either as structured data or as free-text. These data are generally individual personbased records, but social care data are generally case based and less formal data sources may be shared by groups. The structured data may be organised in a proprietary way or be coded using one-of-many coding, classification or terminologies that have often evolved in isolation and designed to meet the needs of the context that they have been developed. This has resulted in a wide range of semantic interoperability issues that make the integration of data held on these different systems changing. We present semantic interoperability challenges and describe a classification of these. We propose a four-step process and a toolkit for those wishing to work more ontologically, progressing from the identification and specification of concepts to validating a final ontology. The four steps are: (1) the identification and specification of data sources; (2) the conceptualisation of semantic meaning; (3) defining to what extent routine data can be used as a measure of the process or outcome of care required in a particular study or audit and (4) the formalisation and validation of the final ontology. The toolkit is an extension of a previous schema created to formalise the development of ontologies related to chronic disease management. The extensions are focused on facilitating rapid building of ontologies for time-critical research studies.",2015/07/10/,2015,"2058-4563, 2058-4555",Journal of Innovation in Health Informatics,309,315,,,10.14236/jhi.v22i2.159,,en,,,,,[],['https://informatics.bmj.com/lookup/doi/10.14236/jhi.v22i2.159'],DOI.org (Crossref),22,2,jhi,,2025/10/04/14:38:29,,,1,2025-10-19 20:23:59,
47,CONF,Open Government Data on the Web: A Semantic Approach,"['Hoxha, Julia', 'Brahaj, Armand']","Initiatives of making government data open are continuously gaining interest recently. While this presents immense benefits for increasing transparency, the problem is that the data are frequently offered in heterogeneous formats, missing clear semantics that clarify what the data describe. The data are displayed in ways, which are not always clearly understandable to a broad range of user communities that need to make informed decisions.",2011/09//,2011,978-1-4577-0840-4,2011 International Conference on Emerging Intelligent Data and Web Technologies (EIDWT),107,113,IEEE,2011 International Conference on Emerging Intelligent Data and Web Technologies,10.1109/EIDWT.2011.24,,en,,,,"Tirana, Albania",[],['http://ieeexplore.ieee.org/document/6076428/'],DOI.org (Crossref),,,,Open Government Data on the Web,2025/10/04/14:38:37,,,1,2025-10-19 20:24:16,
33,JOUR,A comprehensive survey on semantic interoperability for Internet of Things: State‐of‐the‐art and research challenges,"['Rahman, Hafizur', 'Hussain, Md. Iftekhar']","Internet of Things (IoT) is highly heterogeneous in terms of devices, communication technologies, protocols, data formats, and semantics. Data generated from various sources are represented using different semantics. It makes semantic interoperability as one of the significant issues in provisioning seamless communication and services over diverse IoT platforms. Semantic models help in exchanging semantically annotated information among such heterogeneous applications in a meaningful way. Seamless communication among different types of applications is commonly accomplished by using middleware, ontology, and semantic web technologies. In this paper, we present a comprehensive survey of different semantic interoperability solutions in the context of IoT. The pivotal semantic models available in the literature are compared with the help of a classification framework. This study identifies various open research issues and challenges for facilitating interoperable IoT communications. For the purpose of implementation and performance evaluation of various semantic models, we also suggest some important tools and frameworks. After pointing out different prospects and problems of the existing semantic interoperability schemes, the factors for improvement are identified indicating future research directions.",2020/12//,2020,"2161-3915, 2161-3915",Transactions on Emerging Telecommunications Technologies,e3902,,,,10.1002/ett.3902,,en,,,,,[],['https://onlinelibrary.wiley.com/doi/10.1002/ett.3902'],DOI.org (Crossref),31,12,Trans Emerging Tel Tech,A comprehensive survey on semantic interoperability for Internet of Things,2025/10/04/14:38:16,,,1,2025-10-19 20:25:47,
27,CONF,An Overview of Semantic Interoperability Ontologies and Frameworks for IoT,"['Nagowah, Soulakshmee Devi', 'Ben Sta, Hatem', 'Gobin-Rahimbux, Baby Ashwin']",Interoperability is one of the key challenges that needs to be addressed to realize the vision of the Internet of Things (IoT). Achieving interoperability in IoT will allow billions of devices to communicate and exchange information to perform jobs. Formalized ways are required to express needs and capabilities of these devices as well as services to be offered by the devices and these can be achieved by using semantics. Semantic interoperability is thus defined as unambiguous access and interpretation of data by different stakeholders. The paper presents the challenges and current solutions of semantic interoperability. It also discusses the limitations of the current solutions in IoT and recommends a way forward.,2018/10//,2018,978-1-5386-8388-0,2018 Sixth International Conference on Enterprise Systems (ES),82,89,IEEE,2018 Sixth International Conference on Enterprise Systems (ES),10.1109/ES.2018.00020,,en,,,,Limassol,[],['https://ieeexplore.ieee.org/document/8588262/'],DOI.org (Crossref),,,,,2025/10/04/14:38:05,,,1,2025-10-19 20:26:25,
22,JOUR,Building Semantic Webs for e-government with Wiki technology,"['Wagner, Christian', 'Cheung, Karen S K', 'Ip, Rachael K F', 'Böttcher, Stefan']","E-government webs are among the largest webs in existence, based on the size, number of users and number of information providers. Thus, creating a Semantic Web infrastructure to meaningfully organise e-government webs is highly desirable. At the same time, the complexity of the existing e-government implementations also challenges the feasibility of Semantic Web creation. We therefore propose the design of a two-layer semantic Wiki web, which consists of a content Wiki, largely identical to the traditional web and a semantic layer, also maintained within the Wiki, that describes semantic relationships. This architectural design promises several advantages that enable incremental growth, collaborative development by a large community of non-technical users and the ability to continually grow the content layer without the immediate overhead of parallel maintenance of the semantic layer. This paper explains current challenges to the development of a Semantic Web, identifies Wiki advantages, illustrates a potential solution and summarises major directions for further research.",,,,,,,,,10.1504/EG.2006.008491,,en,,,,,[],,Zotero,,,,,,,,1,2025-10-19 20:27:56,
44,JOUR,How to establish a common ground for semantic interoperability within e-government communities,"['Klischewski, Ralf']","The aim of this contribution is to discuss how we could reach a common ground for semantic interoperability without the idea that all actors involved should adopt one world view, i.e. a certain perspective on what exists and how it is related as provided through one overall ontology and/or markup language. Firstly, the role of ontologies as a means for semantic interoperability in e-government is examined. Secondly, it is investigated how differences in ontology interpretation and related interoperability strategies may lead to difficulties to reach for interoperability agreements. Thirdly, based on Semantic Web research already available, some guidelines are suggested how e-government communities can reconcile the differences and a reach a common ground for semantic interoperability.",,,,,,,,,,['⛔ No DOI found'],en,,,,,[],,Zotero,,,,,,,,1,2025-10-19 20:28:35,
9,CHAP,Evaluating SPARQL-based model checking: Potentials and limitations,"['Hoffmann, A', 'Shi, M', 'Wagner, A', 'Thiele, C-D', 'Huyeng, T-J', 'Rüppel, U', 'Sprenger, W']","Model checking is an important task in the BIM collaboration process to prevent expensive planning errors. The submodels of the individual disciplines are transferred into a coordination model. Part of the transfer is a conversion into an exchange format. The exchange format allows the import into the model checking application. In the model checking application routines are performed to check the model against collisions and building regulation violations. During the transfer into the exchange format, information may get lost, especially with parameters that are not yet part of the exchange format supported by the authoring software. In recent years, ontologies have been investigated as a feasible approach to combine the submodels, since they model data in a flexible manner. Hence in the conversion process to an application-specific ontology, the data structure of the submodels can widely persist, which could lead to smaller information loss in comparison to converting the data into a standardized exchange format. The evaluation of the geometric properties of the building is indispensable for detecting and analyzing collisions. The basis for the connection of the different sub models could be the BOT (Building Topology Ontology), which defines the topological structure of a building and can be used to represent further building information by linking it with other ontologies. The relevant geometric relationships for the collision model checks have to be derived with a geometry kernel. For the research in this paper pythonOCC, a wrapper for the geometry kernel Open CASCADE is used with the Semantic Web's own query language SPARQL, queries can be formulated to analyze the collision relationships in combination with other semantic information. These queries can be used to verify model correctness. By connecting the information from different domains, more sophisticated tests are possible than in an exchange format dependent model checking application. The goal is to integrate the developed functionalities into a project platform. This platform is based on an extensive project description in an ontology-based data model and is connected to different authoring tools for the exchange of information.",2021///,2021,,"ECPPM 2021-eWork and eBusiness in architecture, engineering and construction",83,90,CRC Press,,,,,,,,,[],,,,,,,,,,1,2025-10-19 20:31:09,
49,JOUR,Integration of Government Services using Semantic Technologies,"['Hreño, Ján', 'Bednár, Peter', 'Furdik, Karol', 'Sabol, Tomáš']","The paper describes an approach to semantic interoperability of eGovernment services applied within the 027020 FP6 IST Access-eGov project. The goal of the project was to improve accessibility and connectivity of governmental services for citizens and businesses by means of creating integrated scenarios and providing guidance to users while following this scenario. The scenario helps the user to identify and fulfil any needed electronic or real governmental services in a selected life situation. The Access-eGov project has developed software tools enabling service integration using semantic technologies. In addition to that, a methodology providing guidance to the user-driven process of creating ontologies was developed. Sample ontologies were prepared for trial applications. The developed tools support browsing, discovery, and execution of government services according to a selected life event or goal. The project successfully developed and tested the proposed solutions. The software developed within the project is available as open source software.",2020///,2020,0718-1876,Journal of theoretical and applied electronic commerce research,143,154,,,10.4067/S0718-18762011000100010,,en,,,,,[],['http://www.scielo.cl/scielo.php?script=sci_arttext&pid=S0718-18762011000100010&lng=en&nrm=iso&tlng=en'],DOI.org (Crossref),6,1,J. theor. appl. electron. commer. res.,,2025/10/04/14:38:40,,,1,2025-10-19 20:32:25,
12,CONF,Decentralization in industry 4.0 supported by opc ua multi-domain information models: Case study and implementation challenges,"['Pribiš, Rudolf', 'Beňo, Lukáš', 'Pajpach, Martin', 'Drahoš, Peter', 'Kocák, Ondrej']","This paper introduces an OPC UA multi-domain information model aimed at supporting decentralization in industrial automation and includes a case study addressing the implementation challenges associated with integrating standards such as Device, PackML, ISA95, and AAS. The developed model enables interoperability and harmonization of information models across various domains, which is crucial for Industry 4.0 applications. The work highlights the paradox of decentralization, where independent modules require centralized control and data coordination, necessitating a unified information model. Key contributions include the proposal of methods to address technical challenges related to data type compatibility and inheritance of properties across domains. Additionally, the text emphasizes the importance of system integration for data acquisition from physical assets. A comparative analysis of implementation on PLCs, on-premises computing platforms, and cloud environments highlights tradeoffs in deployment depending on system complexity and response time requirements. The study results may assist in developing an information model for a decentralized unit in Industry 4.0.",2025/02//,2025,,,1,6,,2025 cybernetics & informatics (K&I),10.1109/KI64036.2025.10916421,"['Interoperability', 'multi-domain information model', 'Data models', 'Computational modeling', 'decentralization', 'Fourth Industrial Revolution', 'Industry 4.0', 'OPC UA', 'Proposals', 'Servers', 'Standards', 'Synchronization', 'System integration', 'Time factors']",,,,,,[],,,,,,,,,,1,2025-10-19 20:36:22,
7,CONF,An Ontology-Driven Approach to Electronic Document Structure Design,"['Nikiforov, Denis A.', 'Korchagin, Alexander B.', 'Sivakov, Ruslan L.']","Over the course of history, humankind used documents as one of the ways of organization of the data. In the recent decades, electronic documentation became increasingly widespread. To make electronic documents exchange possible, standards regulating transmission protocols, representation formats, and rules for document building are necessary. For some protocols (HTTP, SOAP, etc.) and formats (EDI, XML, JSON, etc.), relatively fixed and generally accepted standards are available. As for the electronic document design, there is an abundance of approaches where a leader could hardly be established; all of them have their benefits and drawbacks. This study explores some of these approaches (UN/CEFACT CCTS, WCO DM, ISO 20022, and NIEM). These approaches have different features but from the conceptual perspective they are intended to describe sets of details of some real-world objects. The paper proposes to describe such objects using an ontology and then, based on this ontology, build conceptual structures of electronic documents that can be converted to platform-independent structures of electronic documents in accordance with one of the standards. The introduced approach allows harmonizing the standards under consideration.",2017///,2017,978-3-319-52920-2,,3,16,Springer International Publishing,"Analysis of Images, Social Networks and Texts",,,,,,"['Ignatov, Dmitry I.', 'Khachay, Mikhail Yu.', 'Labunets, Valeri G.', 'Loukachevitch, Natalia', 'Nikolenko, Sergey I.', 'Panchenko, Alexander', 'Savchenko, Andrey V.', 'Vorontsov, Konstantin']",Cham,[],,,,,,,,,,1,2025-10-19 20:37:05,
11,CONF,Multi-domain data modeling for biometrics,"['Chen, Alex', 'Kinser, Jason']","Recently, much work has been performed on CBIR (content based image retrieval) that treats images as single data domain. However, in our highly digitized society, information is being supplied in multiple domains where the data is linked across domains. For example, a web site does contain images, but it may also contain text, hyperlinks, documents, sound files, movies, and other domains of data. Performing recall operations within single domains eliminates the possibility of employing cross-domain inferences. In this work, a multi-domain search space is presented in with two domains: speech and facial images. A single search space is created that contains data from these vastly different domains and cross-domain inferences are allowed. In other words, queries in the speech domain can retrieve image data even if there was no hard link between these data samples. Generation of multidomain search spaces will eventually expand CBIR systems to include data from a variety of sources.",2011/10//,2011,,,1,5,,2011 IEEE applied imagery pattern recognition workshop (AIPR),10.1109/AIPR.2011.6176354,"['Accuracy', 'Biometrics', 'Data domains', 'Data models', 'data query', 'Face', 'Image color analysis', 'IsoMap', 'Speech', 'Vectors']",,,,,,[],,,,,,,,,,1,2025-10-19 20:38:16,
48,CONF,Metadata standards for semantic interoperability in electronic government,"['Davies, Jim', 'Harris, Steve', 'Crichton, Charles', 'Shukla, Aadya', 'Gibbons, Jeremy']","Eﬀective data sharing, across government agencies and other organisations, relies upon agreed meanings and representations. A key, technological challenge in electronic governance is to ensure that the meaning of data items is accurately recorded, and accessible in an economical—eﬀectively, automatic—fashion. In response, a variety of data and metadata standards have been put forward: from government departments, from industry groups, and from organisations such as the ISO and W3C.",2008/12//,2008,978-1-60558-386-0,ICEGOV '08: 2nd International Conference on Theory and Practice of Electronic Governance,67,75,ACM,Proceedings of the 2nd international conference on Theory and practice of electronic governance,10.1145/1509096.1509111,,en,,,,Cairo Egypt,[],['https://dl.acm.org/doi/10.1145/1509096.1509111'],DOI.org (Crossref),,,,,2025/10/04/14:38:39,,,1,2025-10-19 20:38:25,
29,JOUR,A review of electronic government interoperability frameworks: patterns and challenges,"['Charalabidis, Yannis', 'Lampathaki, Fenareti', 'Kavalaki, Alexandra', 'Askounis, Dimitrios']",,2010///,2010,"1742-7509, 1742-7517",International Journal of Electronic Governance,189,,,,10.1504/IJEG.2010.034095,,en,,,,,[],['http://www.inderscience.com/link.php?id=34095'],DOI.org (Crossref),3,2,IJEG,A review of electronic government interoperability frameworks,2025/10/04/14:38:09,,,0,2025-10-19 19:59:36,No abstract
55,BOOK,Semantic Technologies for E-Government,,,2010///,2010,978-3-642-03506-7 978-3-642-03507-4,,,,Springer Berlin Heidelberg,,,,en,,"Berlin, Heidelberg",,,[],['http://link.springer.com/10.1007/978-3-642-03507-4'],DOI.org (Crossref),,,,,2025/10/04/14:38:48,,"['Vitvar, Tomas', 'Peristeras, Vassilios', 'Tarabanis, Konstantinos']",0,2025-10-19 20:00:15,No abstract
3,THES,Class association rule mining using multidimensional numbered information spaces,"['MITOV, Iliya']","Data mining is of great importance in the overall process of knowledge discovery. In this dissertation we focused our attention in the part of discoveryoriented methods and especially classification algorithms. Class-Association Rules (CAR) algorithms have a special place within the family of classification algorithms. This type of classifiers offers a number of advantages: efficiency of the training regardless of the training set; easy handling with high dimensionality; very fast classification; high accuracy; classification model easily comprehensible for humans. The main classification workflow of CAR algorithms usually involves three phases: generating the rules, pruning, and recognition. The mining of association rules is a typical data mining task that works in an unsupervised manner. A major advantage of association rules is that they are theoretically capable to reveal all interesting relationships in a database. But for practical applications the number of mined rules is usually too large to be exploited entirely. Hence, a pruning phase is applied in order to build accurate and compact classifiers. The pruning can be applied during preprocessing, simultaneously to the association rules mining, or during post-processing. Different rule quality measures and rule ordering schemes can be applied in the process of rule selection. There are also different options which can be considered for the recognition phase – e.g. to use a simple rule or to use a set of rules with different types of ordering schemas. On the other hand, the process of creating classification models inevitably touches upon the use of appropriate access methods which facilitate access to different kinds of structures used in such algorithms. Our effort had been focused on the memory organization called Multidimensional numbered information spaces which allows to operate with contextfree multidimensional data structures. The program realization of such structures is named ArM 32. Multi-Domain Information Model (MDIM) and respectively Arm 32 are based on the process of replacing names by numbers which allows to use mathematical functions and addressing vectors for accessing the information. Our approach is to use such structures and operations in the implementation of one class association rule classifier in order to provide evidence on the vitality of the idea of using context-free multidimensional data structures and direct access as a powerful tool for knowledge discovery. We have proposed two classification algorithms – Pyramidal Growing Networks (PGN) and Multi-layer Pyramidal Growing Networks (MPGN). PGN creates association rules, optimized for maximal accuracy of produced rules. One of the main characteristics of PGN is that it is a parameter-free classifier. The association rule mining is executed from the longest rules to the shorter ones until no intersections between patterns in the classes are possible. In the pruning phase the contradictions and inconsistencies of more general rules are cleared, after that the pattern set is compacted excluding all more concrete rules within the classes. PGN is introduced as a useful tool for questioning the support-first principle used by many associative classifiers when mining for association rules. PGN reverses the common approach and focuses primarily on the confidence of the association rules and only in a later stage on the support of the rules. The main purpose is twofold: to provide a proof of concept for this new approach and to gather evidence on its potential. MPGN is based on multilayer structure. It involves possibility to escape combinatorial explosion using smart disposing of the information in the multilayer structures called ""pyramids"". These structures can be easily implemented using ArM-structures. These algorithms are implemented in the data mining environment PaGaNe, developed by the team from the Institute of Mathematics and Informatics – Bulgarian Academy of Sciences; Iliya Mitov and Krassimira Ivanova are the principal developers. PaGaNe incorporates different types of statistical analysis methods, discretization algorithms, association rule miner, as well as classification algorithms, which all are based on the use of multi-dimensional numbered information spaces. The Lenses dataset is used as a test example to illustrate the specifics of the proposed algorithms, the process of creating classification models as well as the process of recognition. We demonstrate that PGN produces the pattern set that is both minimal and complete for covering the learning set, which is an indicator for expectation that PGN will produce tight model and good accuracy results. In the case of MPGN we have demonstrated the process of creating main construction elements. We also have illustrated the functionality which allows to visualize how the pyramids are being created and how the queries are being recognized. We carried out experiments with 25 datasets from the UCI machine learning repository [Frank and Asuncion, 2010]. The experiments had been conducted using the data mining environment PaGaNe, the knowledge analysis system Weka, and LUCS-KDD Repository. A comparison between PGN, MPGN and some other CAR algorithms, as well as decision tree and decision rule classifiers which have similar behavior of creating the task model, had been done. One series of experiments aimed to study what accuracy had been obtained while preprocessing real data with different discretizators realized in PaGaNe. We found that in general PGN-classifier trained on data preprocessed by Chimerge with 95trained on data preprocessed by the other discretization methods. The main reason for this is that using Chi-square statistical measure as criterion for class dependency in adjacent intervals of a feature results in good separation between class labels. A second set of experiments studied the process of growing the learning sets and how this reflects on the classification model and the accuracy of PGN and MPGN; more specifically, we studied the critical point of the amount of the learning set in which classification model is relatively compact and the received accuracy stabilizes. Of course this critical point highly depends on the choice of dataset. A third set of experiments were focused on analyzing different exit points of MPGN. The received results showed that in a lot of cases the build constructs lead to excluding only one class as best competitor. Other cases usually fall into competition between classes, where different strategies for ordering the competitors can be applied. A very few cases fall into the way where MPGNalgorithm did not work and alternative choice is given. A fourth set of experiments aimed to analyze the dependencies of classifiers' behaviors when the noise rush in the dataset attributes; for this set we used the Monks1 dataset. The experiments demonstrated that noising in the dataset worsens considerably the accuracy of PGN which had been designed to perform well in clear datasets. However, experiments with other existing classifiers showed that they also were not been able to resist noising attacks. We made the comparison of overall accuracy between PGN, MPGN (with two recognition strategies – S1 and S2), CMAR, OneR, JRip, J48 and REPTree. The Friedman test showed statistical difference between tested classifiers. The post-hoc Nemenyi test showed that our PGN has best overall performance between examined classifiers and MPGN is competitive with CMAR, J48, JRip and REPTree. The experimental results are very positive and show that PGN is competitive with classification methods that build similar classification behavior. At the same time, it has an essential advantage over the other classifiers being parameter free. Furthermore, the empirical results showed that PGN is slightly more sensitive to noise than techniques such as C4.5 and RIPPER. However, its overall accuracy was still very good compared to these classifiers. In general, the results provide evidence that the confidence-first approach yields interesting opportunities for knowledge discovery.",2011///,2011,,,,,,,,,en,Phd thesis,,,,[],,,,,,,,,,0,2025-10-19 20:13:47,Nummering MDIMs
6,THES,Storing data using natural language addressing,"['IVANOVA, Krassimira']","Large unstructured or semi-structured datasets require a high level of computational sophistication because operations that are easy at a small scale — such as moving data between machines or in and out of storage, visualizing the data, or displaying results —can all require substantial algorithmic ingenuity. As a data set becomes increasingly massive, it may be infeasible to gather it in one place and analyze it as a whole. Thus, there may be a need for algorithms that operate in a distributed fashion, analyzing subsets of the data and aggregating those results to understand the complete set. One aspect of this is the challenge of data assimilation, in which we wish to use new data to update model parameters without reanalyzing the entire data set. This is essential when new waves of data continue to arrive, or subsets are analyzed in isolation of one another, and one aims to improve the model and inferences in an adaptive fashion — for example, with streaming algorithms [NRC, 2013]. In accordance with the actuality of these problems, firstly in [Mitov, 2011] and after that in [Markov et al, 2013] a new idea has been proposed. It is a method for effective building and storing of pattern sets in multi-layer structures during the process of associative rule mining using the possibilities of multi-dimensional numbered information spaces. The main algorithm was called “MPGN”, an abbreviation from ""Multi-layer Pyramidal Growing Networks of information spaces"". The main goal was to extend the possibilities of network structures by using a special kind of multi-layer memory structures called ""pyramids"", which permits defining and realizing new opportunities. The bottleneck of MPGN became the need to search in billions of values of the association rules’ features to convert instances in numbered arrays (vectors). This is a part of preprocessing step of algorithm (see page 97 of [Mitov, 2011]). The process of numbering took considerable time. After numbering, the MPGN algorithm had shown very good results. This work is aimed to propose a solution of the problem of searching in big index structures by proposing a special kind of hashing, so-called “multi-layer hashing”, i.e. by implementing recursively the same specialized hash function to build and resolve the collisions in hash tables. In other words, the main idea consists in using the specialized hashing functions in depth till it is needed. This approach is called “Natural Language Addressing” (NLA) [Ivanova et al, 2012a; Ivanova et al, 2013a; Ivanova et al, 2013d]. The common sense meaning of the concept “address” is such as a description of the location (of a person or organization), as written or printed on mail as directions for delivery [AHD, 2009]; the conventional form by which the location of a building is described [Collins, 2003]; a sign in front of a house or business carrying the conventional form by which its location is described; [WordNet, 2012]. We will use the concept “address” in the sense accepted in the Computer Science: the code that identifies where a piece of information is stored [WordNet, 2012]; a name or number used in information storage or retrieval that is assigned to a specific memory location; the memory location identified by this name or number [AHD, 2009]. Natural Language Addressing (NLA) is a possibility to access information using natural language words as paths to the information. For this purpose the internal encoding of the letters is used to generate corresponded path. The idea of Natural Language Addressing (NL-Addressing) is very simple. It is based on the computer internal representation of the word as strings of codes in a system of encoding (ASCII, UNICODE, etc.). For example, the ASCII encoding of the word „accession” has the next representation: (97, 99, 99, 101, 115, 115, 105, 111, 110). It may be used as array for multi-layer hashing, which indicates a path to point, where the corresponded information may be stored. The main problem in such approach is that the words have different lengths and, in addition, several words may form one phrase and this way to be assumed as single concept. This means that we need tools for managing multi-layer hashing with variable path lengths in an integrated structure. Due to the complexity of MPGN algorithm and the corresponded program system realized in [Mitov, 2011], their redesign and reprogramming for using NLA have to be done after proving the efficiency of NLA realization. Because of this we will concern several types of semi-structured data: ― small datasets - dictionaries, thesauruses, ontologies; ― middle-size and large RDF triple or quadruple datasets, and will provide corresponded experiments and practical implementation. In accordance with this, the PhD research is aimed to propose information model for NL-addressing and corresponded access method as well as the tools for working in such style, theirs main principles, and storing functions. Results presented in this work were implemented in the Institute of Cybernetics V.M. Glushkov at the National Academy of Sciences of Ukraine, Kiev. They had been used for storing dictionaries, thesauruses, ontologies, and RDF-graphs, extracted from multiple documents from own databases as well as from different internet sources.",2014///,2014,,,,,,,,,en,Phd thesis,,,,[],,,,,,,,,,0,2025-10-19 20:14:55,
36,JOUR,Ontology and Semantic Interoperability,"['Bittner, Thomas', 'Donnelly, Maureen']",,,,,,,,,,,['❓ Multiple DOI'],en,,,,,[],,Zotero,,,,,,https://www.crossref.org/openurl?pid=zoteroDOI@wiernik.org&url_ver=Z39.88-2004&ctx_ver=Z39.88-2004&rfr_id=info%3Asid%2Fzotero.org%3A2&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rft.genre=article&rft.atitle=Ontology%20and%20Semantic%20Interoperability&rft.aufirst=Thomas&rft.aulast=Bittner&rft.au=Thomas%20Bittner&rft.au=Maureen%20Donnelly&rft.language=en,,0,2025-10-19 20:28:46,No Abstract
2,CONF,Multi-domain virtual network embedding with coordinated link mapping,"['Li, Shuopeng', 'Saidi, Mohand Yazid', 'Chen, Ken']","Network Virtualization, which allows the coexistence of various logical networks on shared physical infrastructure, has become popular in recent years. The optimal mapping of virtual resource to physical resource is a major issue in network virtualization. This problem, called virtual network embedding (VNE), has been well explored in the context of one physical domain, which is in practice operated by a single infrastructure provider (InP). However, the needs of virtual network (VN) is rapidly growing, and quite a number of VNs have to be established across multi-domain. For multi-domain VNE, infrastructure providers can no longer just solve their own single domain VNE problem, but have to cooperate to build the whole VN. Therefore, new challenge arises for the multi-domain VNE, compared to traditional single domain VNE. The existing investigations on this problem mainly focus on decomposing a VN to sub VN for each domain, but little attention has been paid to the joint relation between intra-domain and inter-domain (peering) links. In this paper, we propose a multi-domain link mapping method which combines the intra and peering link mapping so as to optimize the overall resource utilization. Our approach is easy to be deployed since it is based on current Internet architecture. Evaluation shows that our approach brings improvements related to existing methods.",2016///,2016,,,1,6,,"2016 24th international conference on software, telecommunications and computer networks (SoftCOM)",10.1109/SOFTCOM.2016.7772158,"['Bandwidth', 'III-V semiconductor materials', 'Indium phosphide', 'Peer-to-peer computing', 'Substrates', 'Topology', 'Virtualization']",,,,,,[],,,,,,,,,,0,2025-10-19 20:33:56,On Networking
13,CONF,Big data addressed in natural language,"['Markova, Vera', 'Ivanova, Krasimira', 'Karastanev, Stefan']","Actions related to the cloud processing of large volumes of semi- or unstructured, streaming data (so-called “Big Data”) pose challenges that organizations must address. They are related to the location of the data in the cloud, its storage and management. Much of Big Data is collected from sources that are external to the business organization, such as social media, demographics, web data, events, news sources, and more. In this article, we discuss an access method to enable support for very large Big Data databases. It is based on the capabilities of Natural Language Addressing (NLA). An important advantage of NLA is the reduction of the amount of occupied memory due to the complete absence of additional indexes, absolute addresses, pointers and additional files, as well as the reduction of processing time due to the complete absence of searches - data is stored / retrieved to / from a direct address.",2023/12//,2023,,,53,57,,2023 international conference on advanced enterprise information system (AEIS),10.1109/AEIS61544.2023.00016,"['Data models', 'Big Data', 'big data databases', 'BigNLA access method', 'Memory management', 'natural language addressing', 'Natural languages', 'Organizations', 'Social networking (online)', 'Task analysis']",,,,,,[],,,,,,,,,,0,2025-10-19 20:34:27,Natural Language Addressing
10,CONF,Building data warehouses using numbered information spaces,"['Markov, Krassimir']",An approach for organizing the information in the data warehouses is presented in the paper. The possibilities of the numbered information spaces for building data warehouses are discussed. An application is outlined in the paper.,2006///,2006,,,201,,,Fourth international conference INFORMATION RESEARCH and APPLICATIONS,,['⛔ No DOI found'],,,,,,[],,,,,,,,,,0,2025-10-19 20:34:34,
39,CHAP,Methodological Guidelines for Publishing Government Linked Data,"['Villazón-Terrazas, Boris', 'Vilches-Blázquez, Luis. M.', 'Corcho, Oscar', 'Gómez-Pérez, Asunción']",,2011///,2011,978-1-4614-1766-8 978-1-4614-1767-5,Linking Government Data,27,49,Springer New York,,,,en,,"New York, NY","['Wood, David']",,[],['https://link.springer.com/10.1007/978-1-4614-1767-5_2'],DOI.org (Crossref),,,,,2025/10/04/14:38:23,,,0,2025-10-19 20:34:44,No Abstract
56,JOUR,Metadata interoperability in public sector information,"['Bountouri, Lina', 'Papatheodorou, Christos', 'Soulikias, Vasilis', 'Stratis, Mathios']",,2009///,2009,,Journal of Information Science,204,231,,,10.1177/0165551508098601,,,,,,,[],,,35,2,,,,,,0,2025-10-19 20:34:54,No Abstract
31,JOUR,Towards the government transformation: An ontology-based government knowledge repository,"['Sourouni, Aikaterini-Maria', 'Kourlimpinis, George', 'Mouzakitis, Spiros', 'Askounis, Dimitris']",,2010/01//,2010,09205489,Computer Standards & Interfaces,44,53,,,10.1016/j.csi.2009.06.002,,en,,,,,[],['https://linkinghub.elsevier.com/retrieve/pii/S0920548909000579'],DOI.org (Crossref),32,1-2,Computer Standards & Interfaces,Towards the government transformation,2025/10/04/14:38:13,,,0,2025-10-19 20:38:38,No Abstract
16,JOUR,"Government 2.0: Making connections between citizens, data and government","['Chun, Soon Ae', 'Shulman, Stuart', 'Sandoval, Rodrigo', 'Hovy, Eduard']",,2010/08/04/,2010,"18758754, 15701255",Information Polity,1,9,,,10.3233/IP-2010-0205,,en,,,,,[],['https://journals.sagepub.com/doi/full/10.3233/IP-2010-0205'],DOI.org (Crossref),15,"1,2",IP,Government 2.0,2025/10/04/14:37:10,,,0,2025-10-19 20:38:48,No Abstract
30,JOUR,Model-driven eGovernment interoperability: A review of the state of the art,"['Peristeras, Vassilios', 'Tarabanis, Konstantinos', 'Goudos, Sotirios K.']",,2009/06//,2009,09205489,Computer Standards & Interfaces,613,628,,,10.1016/j.csi.2008.09.034,,en,,,,,[],['https://linkinghub.elsevier.com/retrieve/pii/S0920548908001372'],DOI.org (Crossref),31,4,Computer Standards & Interfaces,Model-driven eGovernment interoperability,2025/10/04/14:38:11,,,0,2025-10-19 20:39:07,No Abstract
28,BOOK,Semantic interoperability of distributed geo-services,"['Lemmens, Rob']",,2006///,2006,978-90-6132-298-6,,,,"NCG, Nederlandse Commissie voor Geodesie, Netherlands Geodetic Commission",,,,en,,Delft,,,[],,Open WorldCat,,,,,,,,0,2025-10-19 20:39:14,No Abstract
15,JOUR,Semantic Annotation for Process Models:,"['Lin, Yun']",,,,,,,,,,,['⛔ No DOI found'],en,,,,,[],,Zotero,,,,,,,,0,2025-10-19 20:39:25,No Abstract
14,CHAP,Industrial Digitally Prototypes,"['Niemann, Jörg', 'Pisla, Adrian']",The whole product lifetime can be firstly defined into 5 major phases.,2021///,2021,978-3-030-56449-0,Life-Cycle Management of Machines and Mechanisms,323,353,Springer International Publishing,,,,,,Cham,"['Niemann, Jörg', 'Pisla, Adrian']",,[],['https://doi.org/10.1007/978-3-030-56449-0_17'],,,,,,,,,0,2025-10-19 20:39:46,Digital Prototypes
0,BOOK,Natural Language Addressing,"['Markov, Krassimir', 'Ivanova, Krassimira', 'Velychko, Vitalii', 'Vanhoof, Koen']","Large unstructured or semi-structured datasets require a high level of computational sophistication because operations that are easy at a small scale — such as moving data betweenmachines or in and out of storage, visualizing the data, or displaying results —can all require substantial algorithmic ingenuity. As a data set becomes increasingly massive, it may be infeasible to gather it in one place and analyze it as a whole. Thus, there may be a need for algorithms that operate in a distributed fashion, analyzing subsets of the data and aggregating those results to understand the complete set. One aspect of this is the challenge of data assimilation, in which we wish to use new data to update model parameters without reanalyzing the entire data set. This is essential when new waves of data continue to arrive, or subsets are analyzed in isolation of one another, and one aims to improve the model and inferences in an adaptive fashion — for example, with streaming algorithms [NRC, 2013].",2015/11/05/,2015,"978-954-16-0070-2 (printed), 978-954-16-0071-9 (online)",,,,,,,,,,,,,[],,,,,,,,,,0,2025-10-19 20:41:11,Strategie Grote datasets
8,CONF,ArmSquare: An association rule miner based on multidimensional numbered information spaces,"['MITOV, Iliya', 'IVANOVA, Krassimira', 'DEPAIRE, Benoit', 'VANHOOF, Koen']","In this article, we propose a simple approach for association rule mining, which uses the possibilities of the multidimensional numbered information spaces as a storage structures. The main focus in the realization of ArmSquare is using the advantages of such spaces, i.e., the possibility to build growing space hierarchies of information elements, the great power for building interconnections between information elements stored in the information base, and the possibility to change searching with direct addressing in well structured tasks. The tested types of implementations of realized tool show the vividness of proposed approach.",2011///,2011,978-1-61839-702-7,,143,148,"Curran Associates, Inc.",Proceedings of the 1st international conference on advances in information mining and management,,"['Association Rule Mining', 'Market Basket Analysis', 'Multidimensional Numbered Information Spaces']",en,,,,,['1st International Conference on Advances in Information Mining and Management'],,,,,,,,,,0,2025-10-19 20:41:32,Numbered Information Spaces
38,JOUR,E-Government Interoperability: Linking Open and Smart Government,"['Jiménez, Carlos E.', 'Solanas, Agusti', 'Falcone, Francisco']",,2014/10//,2014,"0018-9162, 1558-0814",Computer,22,24,,,10.1109/MC.2014.281,,en,,,,,[],['https://ieeexplore.ieee.org/document/6926731/'],DOI.org (Crossref),47,10,Computer,E-Government Interoperability,2025/10/04/14:38:22,,,0,2025-10-19 20:41:41,No Abstract
5,CHAP,Storing RDF graphs using NL-addressing,"['IVANOVA, Krassimira', 'Velychko, Vitalii', 'MARKOV, Krassimir']","NL-addressing is a possibility to access information using natural language words as addresses of the information stored in the multi-dimensional numbered information spaces. For this purpose the internal encoding of the letters is used to generate corresponded co-ordinates. The tool for working in such style is named OntoArM. Its main principles, functions and using for storing RDF graphs are outlined in this paper",2012///,2012,978-954-16-0057-3,Artificial intelligence methods and techniques for business and engineering applications,84,98,ITHEA® 2012,,,"['NL-addressing', 'ontology representations.', 'RDF graphs', 'review: test']",en,,"Rzeszow, Poland; Sofia, Bulgaria",,,[],,,,,,,,,,0,2025-10-19 20:42:07,Numbered Information Spaces
4,BOOK,About NL-addressing,"['IVANOVA, Krassimira', 'Velychko, Vitalii', 'MARKOV, Krassimir']","В настоящей работе представлена идея естественно-языковой адресации. Это дополнительная возможность для представления онтологической информации в интеллектуальных системах. Естественно-языковая адресация имеет ряд преимуществ. На первом месте – это линейная алгоритмическая сложность, которая зависит от максимальной длины слов (max_L), а не от их количества. Во-вторых, это уменьшение объема занимаемой памяти – дополнительные индексы не используются. В-третьих, уменьшение времени обработки из-за полного отсутствия поиска – информация извлекается прямо по адресу. Необходимо отметить, что это универсальное представление информации одновременно доступной как для человека, так и для автоматизированных систем. Такой способ организации информации применим для ее хранения и использования в библиотеках онтологий, терминов, понятий, текстовых документов",2012///,2012,978-954-16-0061 0,Problems of computer intellectualization,,,ITHEA® 2012,,,"['Естественно-языковая адресация', 'организация онтологических баз данных']",other,,"Kiev, Ukraine - Sofia, Bulgaria",,,[],,,,,,,,,,0,2025-10-19 20:42:49,Language out of bounds
1,CHAP,""" PaGaNe""–a CLASSIFICATION MACHINE LEARNING SYSTEM BASED on the MULTIDIMENSIONAL NUMBERED INFORMATION SPACES","['MITOV, ILIA', 'IVANOVA, KRASSIMIRA', 'MARKOV, KRASSIMIR', 'VELYCHKO, VITALII', 'VANHOOF, KOEN', 'STANCHEV, PETER']","A classification machine learning system ""PaGaNe"" based on the multidimensional numbered information spaces for memory structuring is presented in the paper. Testing results, which show the efficiency of chosen approach, are presented.",2010///,2010,,Intelligent decision making systems,279,286,World Scientific,,,,,,,,,[],,,,,,,,,,0,2025-10-19 20:43:10,Numbered Information Spaces
